{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.set_option('display.width', 85)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# load tabular structure JSON data\n",
    "with open('data/allcandidatenewssample.json') as f:\n",
    "  candidatenews = json.load(f)\n",
    "\n",
    "\n",
    "len(candidatenews)\n",
    "pprint.pprint(candidatenews[0:2])\n",
    "pprint.pprint(candidatenews[0]['source'])\n",
    "\n",
    "Counter([len(item) for item in candidatenews])\n",
    "pprint.pprint(next(item for item in candidatenews if len(item)<9))\n",
    "pprint.pprint(next(item for item in candidatenews if len(item)>9))\n",
    "pprint.pprint([item for item in candidatenews if len(item)==2][0:2])\n",
    "\n",
    "candidatenews = [item for item in candidatenews if len(item)>2]\n",
    "len(candidatenews)\n",
    "\n",
    "# generate counts from JSON data\n",
    "politico = [item for item in candidatenews if item[\"source\"] == \"Politico\"]\n",
    "len(politico)\n",
    "pprint.pprint(politico[0:2])\n",
    "sources = [item.get('source') for item in candidatenews]\n",
    "type(sources)\n",
    "len(sources)\n",
    "sources[0:5]\n",
    "pprint.pprint(Counter(sources).most_common(10))\n",
    "\n",
    "# fix errors in values in dictionary\n",
    "for newsdict in candidatenews:\n",
    "    newsdict.update((k, \"The Hill\") for k, v in newsdict.items()\n",
    "     if k == \"source\" and v == \"TheHill\")\n",
    "\n",
    "sources = [item.get('source') for item in candidatenews]\n",
    "pprint.pprint(Counter(sources).most_common(10))\n",
    "\n",
    "# create a pandas data frame\n",
    "candidatenewsdf = pd.DataFrame(candidatenews)\n",
    "candidatenewsdf.dtypes\n",
    "candidatenewsdf.rename(columns={'date':'storydate'}, inplace=True)\n",
    "candidatenewsdf.storydate = candidatenewsdf.storydate.astype('datetime64[ns]')\n",
    "candidatenewsdf.shape\n",
    "candidatenewsdf.source.value_counts(sort=True).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入 json api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# load more complicated data\n",
    "response = requests.get(\"https://openaccess-api.clevelandart.org/api/artworks/?african_american_artists\")\n",
    "camcollections = json.loads(response.text)\n",
    "\n",
    "len(camcollections['data'])\n",
    "pprint.pprint(camcollections['data'][0])\n",
    "\n",
    "# flatten the data\n",
    "camcollectionsdf = \\\n",
    "  pd.json_normalize(camcollections['data'], \n",
    "  'citations', \n",
    "  ['accession_number','title','creation_date',\n",
    "  'collection','creators','type'])\n",
    "camcollectionsdf.head(2).T\n",
    "creator = camcollectionsdf[:1].creators[0]\n",
    "type(creator[0])\n",
    "pprint.pprint(creator)\n",
    "\n",
    "camcollectionsdf['birthyear'] = camcollectionsdf.\\\n",
    " creators.apply(lambda x: x[0]['birth_year'])\n",
    "\n",
    "camcollectionsdf.birthyear.value_counts().\\\n",
    " sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.width', 85)\n",
    "pd.set_option('display.max_columns',8)\n",
    "\n",
    "# parse the web page and get the header row of the table\n",
    "\n",
    "webpage = requests.get(\"http://www.alrb.org/datacleaning/highlowcases.html\")\n",
    "\n",
    "bs = BeautifulSoup(webpage.text, 'html.parser')\n",
    "theadrows = bs.find('table', {'id':'tblLowCases'}).thead.find_all('th')\n",
    "type(theadrows)\n",
    "labelcols = [j.get_text() for j in theadrows]\n",
    "labelcols[0] = \"rowheadings\"\n",
    "labelcols\n",
    "\n",
    "# get the data from the table cells\n",
    "rows = bs.find('table', {'id':'tblLowCases'}).tbody.find_all('tr')\n",
    "datarows = []\n",
    "labelrows = []\n",
    "for row in rows:\n",
    "  rowlabels = row.find('th').get_text()\n",
    "  cells = row.find_all('td', {'class':'data'})\n",
    "  if (len(rowlabels)>3):\n",
    "    labelrows.append(rowlabels)\n",
    "  if (len(cells)>0):\n",
    "    cellvalues = [j.get_text() for j in cells]\n",
    "    datarows.append(cellvalues)\n",
    "\n",
    "pprint.pprint(datarows[0:2])\n",
    "pprint.pprint(labelrows[0:2])\n",
    "\n",
    "for i in range(len(datarows)):\n",
    "  datarows[i].insert(0, labelrows[i])\n",
    "\n",
    "pprint.pprint(datarows[0:2])\n",
    "\n",
    "labelcols\n",
    "\n",
    "# load the data into pandas\n",
    "lowcases = pd.DataFrame(datarows, columns=labelcols)\n",
    "lowcases.iloc[:,1:5].head()\n",
    "lowcases.dtypes\n",
    "lowcases.columns = lowcases.columns.str.replace(\" \", \"_\").str.lower()\n",
    "\n",
    "#lowcases.columns\n",
    "#fixcols = ['total_cases','total_deaths','total_cases_pm','total_deaths_pm','population','gdp_per_capita']\n",
    "\n",
    "for col in lowcases.columns[2:-1]:\n",
    "  lowcases[col] = lowcases[col].\\\n",
    "    str.replace(\"[^0-9]\",\"\",regex=True).astype('int64')\n",
    "\n",
    "lowcases['last_date'] = pd.to_datetime(lowcases.last_date)\n",
    "lowcases['median_age'] = lowcases['median_age'].astype('float')\n",
    "\n",
    "lowcases.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns',6)\n",
    "\n",
    "# initiate a Spark session and import CSV data\n",
    "spark = SparkSession.builder \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "landtemps = spark.read.option(\"header\",True) \\\n",
    "     .csv(\"data/landtemps.tar.gz\")\n",
    "\n",
    "type(landtemps)\n",
    "\n",
    "# look at the structure of the Spark DataFrame\n",
    "landtemps.count()\n",
    "\n",
    "landtemps.printSchema()\n",
    "\n",
    "landtemps.select(\"station\",'country','month','year','temp') \\\n",
    "    .show(5, False)\n",
    "\n",
    "# chagne a data type\n",
    "landtemps = landtemps \\\n",
    "  .withColumn(\"temp\",landtemps.temp.cast('float'))\n",
    "\n",
    "landtemps.select(\"temp\").dtypes\n",
    "\n",
    "landtemps.describe('temp').show()\n",
    "\n",
    "# load JSON data\n",
    "allcandidatenews = spark.read \\\n",
    "     .json(\"data/allcandidatenewssample.json\")\n",
    "\n",
    "allcandidatenews \\\n",
    "  .select(\"source\",\"title\",\"story_position\") \\\n",
    "  .show(5)\n",
    "\n",
    "# display structure of JSON data\n",
    "allcandidatenews.count()\n",
    "\n",
    "allcandidatenews.printSchema()\n",
    "\n",
    "allcandidatenews \\\n",
    "   .describe('story_position') \\\n",
    "   .show()\n",
    "    \n",
    "allcandidatenewsdf = allcandidatenews.toPandas()\n",
    "\n",
    "allcandidatenewsdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 持久化json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import msgpack\n",
    "\n",
    "pd.set_option('display.width', 85)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# load complicated JSON data from an API\n",
    "response = requests.get(\"https://openaccess-api.clevelandart.org/api/artworks/?african_american_artists\")\n",
    "\n",
    "camcollections = json.loads(response.text)\n",
    "len(camcollections['data'])\n",
    "pprint.pprint(camcollections['data'][0])\n",
    "\n",
    "# save to a json file\n",
    "with open(\"data/camcollections.json\",\"w\") as f:\n",
    "  json.dump(camcollections, f)\n",
    "\n",
    "# read the json file\n",
    "with open(\"data/camcollections.json\",\"r\") as f:\n",
    "  camcollections = json.load(f)\n",
    "\n",
    "pprint.pprint(camcollections['data'][0]['creators'])\n",
    "\n",
    "# Write msgpack file\n",
    "with open(\"data/camcollections.msgpack\", \"wb\") as outfile:\n",
    "    packed = msgpack.packb(camcollections)\n",
    "    outfile.write(packed)\n",
    "\n",
    "# Read msgpack file\n",
    "with open(\"data/camcollections.msgpack\", \"rb\") as data_file:\n",
    "    msgbytes = data_file.read()\n",
    "\n",
    "camcollections = msgpack.unpackb(msgbytes)\n",
    "\n",
    "pprint.pprint(camcollections['data'][0]['creators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据版本控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "ename": "CommitFailedError",
     "evalue": "Writer features must be specified for writerversion >= 7, please specify: TimestampWithoutTimezone",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommitFailedError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m landtemps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/landtempssample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstationid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavgtemp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountryid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     16\u001b[0m landtemps\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 18\u001b[0m \u001b[43mwrite_deltalake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/temps_lake\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandtemps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m tempsdelta \u001b[38;5;241m=\u001b[39m DeltaTable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/temps_lake\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mtype\u001b[39m(tempsdelta)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/deltalake/writer.py:323\u001b[0m, in \u001b[0;36mwrite_deltalake\u001b[0;34m(table_or_uri, data, schema, partition_by, mode, file_options, max_partitions, max_open_files, max_rows_per_file, min_rows_per_group, max_rows_per_group, name, description, configuration, schema_mode, storage_options, partition_filters, predicate, target_file_size, large_dtypes, engine, writer_properties, custom_metadata, post_commithook_properties, commit_properties)\u001b[0m\n\u001b[1;32m    317\u001b[0m data, schema \u001b[38;5;241m=\u001b[39m _convert_data_and_schema(\n\u001b[1;32m    318\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    319\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    320\u001b[0m     conversion_mode\u001b[38;5;241m=\u001b[39mArrowSchemaConversionMode\u001b[38;5;241m.\u001b[39mPASSTHROUGH,\n\u001b[1;32m    321\u001b[0m )\n\u001b[1;32m    322\u001b[0m data \u001b[38;5;241m=\u001b[39m RecordBatchReader\u001b[38;5;241m.\u001b[39mfrom_batches(schema, (batch \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data))\n\u001b[0;32m--> 323\u001b[0m \u001b[43mwrite_deltalake_rust\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_file_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_file_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_commithook_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_commithook_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table:\n\u001b[1;32m    341\u001b[0m     table\u001b[38;5;241m.\u001b[39mupdate_incremental()\n",
      "\u001b[0;31mCommitFailedError\u001b[0m: Writer features must be specified for writerversion >= 7, please specify: TimestampWithoutTimezone"
     ]
    }
   ],
   "source": [
    "from deltalake.writer import write_deltalake\n",
    "from deltalake import DeltaTable\n",
    "import os\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns',6)\n",
    "\n",
    "os.makedirs(\"data/temps_lake\", exist_ok=True)\n",
    "\n",
    "landtemps = pd.read_csv('data/landtempssample.csv',\n",
    "    names=['stationid','year','month','avgtemp','latitude',\n",
    "      'longitude','elevation','station','countryid','country'],\n",
    "    skiprows=1,\n",
    "    parse_dates=[['month','year']])\n",
    "\n",
    "landtemps.shape\n",
    "\n",
    "write_deltalake(\"data/temps_lake\", landtemps)\n",
    "\n",
    "tempsdelta = DeltaTable(\"data/temps_lake\", version=0)\n",
    "type(tempsdelta)\n",
    "tempsdfv1 = tempsdelta.to_pandas()\n",
    "tempsdfv1.shape\n",
    "\n",
    "write_deltalake(\"data/temps_lake\", landtemps.head(1000), mode=\"overwrite\")\n",
    "\n",
    "tempsdfv2 = DeltaTable(\"data/temps_lake\", version=1).to_pandas()\n",
    "tempsdfv2.shape\n",
    "\n",
    "write_deltalake(\"data/temps_lake\", landtemps.head(1000), mode=\"append\")\n",
    "\n",
    "tempsdfv3 = DeltaTable(\"data/temps_lake\", version=2).to_pandas()\n",
    "tempsdfv3.shape\n",
    "\n",
    "DeltaTable(\"data/temps_lake\", version=0).to_pandas().shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
