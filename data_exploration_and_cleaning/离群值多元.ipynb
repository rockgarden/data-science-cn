{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单变量离群值\n",
    "\n",
    "Outliers variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scistat\n",
    "pd.set_option('display.width', 62)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 设置累计栏和人口统计栏\n",
    "totvars = ['location','total_cases',\n",
    "  'total_deaths','total_cases_pm',\n",
    "  'total_deaths_pm']\n",
    "demovars = ['population','pop_density',\n",
    "  'median_age','gdp_per_capita',\n",
    "   'hosp_beds','hum_dev_ind']\n",
    "\n",
    "covidtotals.info()\n",
    "\n",
    "# 获取累积值的描述性统计\n",
    "covidtotalsonly = covidtotals.loc[:, totvars]\n",
    "covidtotalsonly.describe()\n",
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "covidtotalsonly.quantile(np.arange(0.0, 1.1, 0.1),\n",
    "   numeric_only=True)\n",
    "covidtotalsonly.skew(numeric_only=True)\n",
    "covidtotalsonly.kurtosis(numeric_only=True)\n",
    "\n",
    "# 正态性检验\n",
    "def testnorm(var, df):\n",
    "  stat, p = scistat.shapiro(df[var])\n",
    "  return p\n",
    "\n",
    "print(\"total cases: %.5f\" % testnorm(\"total_cases\", covidtotalsonly))\n",
    "print(\"total deaths: %.5f\" % testnorm(\"total_deaths\", covidtotalsonly))\n",
    "print(\"total cases pm: %.5f\" % testnorm(\"total_cases_pm\", covidtotalsonly))\n",
    "print(\"total deaths pm: %.5f\" % testnorm(\"total_deaths_pm\", covidtotalsonly))\n",
    "\n",
    "# 显示病例总数和每百万病例总数的 qqplot 图\n",
    "sm.qqplot(covidtotalsonly[['total_cases']]. \\\n",
    "  sort_values(['total_cases']), line='s')\n",
    "plt.title(\"QQ Plot of Total Cases\")\n",
    "\n",
    "sm.qqplot(covidtotals[['total_cases_pm']]. \\\n",
    "  sort_values(['total_cases_pm']), line='s')\n",
    "plt.title(\"QQ Plot of Total Cases Per Million\")\n",
    "plt.show()\n",
    "\n",
    "# 显示总病例的异常值\n",
    "thirdq, firstq = covidtotalsonly.total_cases.quantile(0.75), covidtotalsonly.total_cases.quantile(0.25)\n",
    "interquartilerange = 1.5*(thirdq-firstq)\n",
    "outlierhigh, outlierlow = interquartilerange+thirdq, firstq-interquartilerange\n",
    "print(outlierlow, outlierhigh, sep=\" <--> \")\n",
    "\n",
    "# 生成离群值表格并保存到 Excel/CSV 中\n",
    "def getoutliers():\n",
    "  dfout = pd.DataFrame(columns=covidtotals. \\\n",
    "    columns, data=None)\n",
    "  for col in covidtotalsonly.columns[1:]:\n",
    "    thirdq, firstq = covidtotalsonly[col].\\\n",
    "      quantile(0.75),covidtotalsonly[col].\\\n",
    "      quantile(0.25)\n",
    "    interquartilerange = 1.5*(thirdq-firstq)\n",
    "    outlierhigh, outlierlow = \\\n",
    "      interquartilerange+thirdq, \\\n",
    "      firstq-interquartilerange\n",
    "    df = covidtotals.loc[(covidtotals[col]> \\\n",
    "      outlierhigh) | (covidtotals[col]< \\\n",
    "      outlierlow)]\n",
    "    df = df.assign(varname = col,\n",
    "      threshlow = outlierlow,\n",
    "      threshhigh = outlierhigh)\n",
    "    dfout = pd.concat([dfout, df])\n",
    "  return dfout\n",
    "\n",
    "outliers = getoutliers()\n",
    "outliers.varname.value_counts()\n",
    "outliers.to_excel(\"views/outlierscases.xlsx\")\n",
    "outliers.to_csv(\"views/outlierscases.csv\")\n",
    "\n",
    "# 再仔细观察一下每百万人死亡数的异常值\n",
    "outliers.loc[outliers.varname==\"total_deaths_pm\",\n",
    "  ['location','total_deaths_pm','total_cases_pm',\n",
    "   'median_age','hum_dev_ind']]. \\\n",
    "  sort_values(['total_deaths_pm'], ascending=False)\n",
    "\n",
    "covidtotals[['total_deaths_pm','median_age',\n",
    "  'hum_dev_ind']]. \\\n",
    "  quantile([0.25,0.5,0.75])\n",
    "\n",
    "# 再次显示病例总数柱状图\n",
    "plt.hist(covidtotalsonly['total_cases']/1000, bins=7)\n",
    "plt.title(\"Total Covid Cases (thousands)\")\n",
    "plt.xlabel('Cases')\n",
    "plt.ylabel(\"Number of Countries\")\n",
    "plt.show()\n",
    "\n",
    "# 对 covid 数据进行对数变换\n",
    "covidlogs = covidtotalsonly.copy()\n",
    "for col in covidlogs.columns[1:]:\n",
    "  covidlogs[col] = np.log1p(covidlogs[col])\n",
    "\n",
    "plt.hist(covidlogs['total_cases'], bins=7)\n",
    "plt.title(\"Total Covid Cases (log)\")\n",
    "plt.xlabel('Cases')\n",
    "plt.ylabel(\"Number of Countries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二维变量离群值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.width', 65)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 生成累积数据和人口统计数据的相关矩阵\n",
    "\n",
    "covidtotals.corr(method=\"pearson\", numeric_only=True)\n",
    "\n",
    "# 看看某些国家的病例数是否会出现意想不到的低死亡率或高死亡率\n",
    "\n",
    "# 分箱操作：根据等级或样本量化值将变量离散成大小相等的桶。\n",
    "covidtotals['total_cases_q'] = pd.\\\n",
    "  qcut(covidtotals['total_cases'],\n",
    "  labels=['very low','low','medium',\n",
    "  'high','very high'], q=5, precision=0)\n",
    "  \n",
    "covidtotals.loc[covidtotals.total_cases_q.notnull(),'hosp_beds'] = \\\n",
    "  covidtotals.loc[covidtotals.total_cases_q.notnull()].\\\n",
    "    groupby(['total_cases_q'])['hospital_beds_thous'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "print(covidtotals[['location','hospital_beds_thous']].head(10))\n",
    "\n",
    "covidtotals['total_deaths_q'] = pd.\\\n",
    "  qcut(covidtotals['total_deaths'],\n",
    "  labels=['very low','low','medium',\n",
    "  'high','very high'], q=5, precision=0)\n",
    "\n",
    "pd.crosstab(covidtotals.total_cases_q,\n",
    "  covidtotals.total_deaths_q)\n",
    "\n",
    "covidtotals.loc[(covidtotals. \\\n",
    "  total_cases_q==\"high\") & \\\n",
    "  (covidtotals.total_deaths_q==\"low\")].T\n",
    "\n",
    "# 将病例总数与死亡总数进行散点图分析\n",
    "ax = sns.regplot(x=covidtotals.total_cases/1000, y=covidtotals.total_deaths)\n",
    "ax.set(xlabel=\"Cases (thousands)\", ylabel=\"Deaths\", title=\"Total Covid Cases and Deaths by Country\")\n",
    "plt.show()\n",
    "\n",
    "covidtotals.loc[(covidtotals.total_cases<40000000) \\\n",
    "  & (covidtotals.total_deaths>400000)].T\n",
    "covidtotals.loc[(covidtotals.total_cases>30000000) \\\n",
    "  & (covidtotals.total_deaths<100000)].T\n",
    "\n",
    "# 将病例总数与死亡总数进行散点图分析\n",
    "ax = sns.regplot(x=\"total_cases_mill\", y=\"total_deaths_mill\", data=covidtotals)\n",
    "ax.set(xlabel=\"Cases Per Million\", ylabel=\"Deaths Per Million\", title=\"Total Covid Cases per Million and Deaths per Million by Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- encoding=utf8 -*-\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "# 分箱填充：根据等级或样本量化值将变量离散成大小相等的桶，取箱中属性值的平均值或中值来替换或生成“箱”中的属性值；\n",
    "\n",
    "# 导入相应数据库客户端\n",
    "import mysql.connector as mdb\n",
    "\n",
    "# 引入并配置 pandas 显示参数\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# 设置目标 table 查询语句以提取数据\n",
    "targettable = \"name\"\n",
    "\n",
    "# 设置 sql 写入语句以修改数据\n",
    "insertsql = 'insert into t_ds_wash_log(wash_type,wash_result,wash_state,process_definition_id,\\\n",
    "    process_instance_id,task_instance_id,create_time)values (%s,%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "# 使用 mysql api 和 read_sql() 从 mysql 获取和加载数据\n",
    "host = \"pdccmysql\"\n",
    "user = \"pdccuser\"\n",
    "password = \"pdccpass\"\n",
    "database = \"pdccschema\"\n",
    "connmysql = mdb.connect(host=host,database=database,user=user,password=password)\n",
    "df = pd.read_sql_table(table_name=targettable,con=connmysql)    # 生成 DataFrame\n",
    "connmysql.close()\n",
    "\n",
    "# 将 DataFrame 中的一个或多个列设置为索引\n",
    "df.set_index([\"column1_name\",'column2_name'], inplace=True)\n",
    "\n",
    "# 指定 column 进行分箱操作，并新增分箱数据列 column_qcut，分箱数据 q 需按数据实际情况取\n",
    "df['column3_qcut'] = pd.\\\n",
    "  qcut(df['column3'],\n",
    "       q=100, precision=0, duplicates='drop')\n",
    "\n",
    "# 通过 column_qcut 分组计算目标 column 的 mean/median 值并对该列的空值进行填充 \n",
    "df.loc[df.column3_qcut.notnull(), 'column4'] = \\\n",
    "  df.loc[df.column3_qcut.notnull()].\\\n",
    "  groupby(['column3_qcut'])['column4'].\\\n",
    "  transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 写入数据库，method = 'multi' 需要数据库支持 \n",
    "df.to_sql(name=targettable,con=connmysql,if_exists='replace',chunksize=1000)\n",
    "connmysql.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 条件选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 55)\n",
    "pd.set_option('display.max_columns', 5)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97f.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 查看一些 NLS 数据\n",
    "nls97[['wageincome20','highestgradecompleted',\n",
    "  'highestdegree']].head(3).T\n",
    "\n",
    "nls97.dtypes\n",
    "\n",
    "nls97.loc[:, \"weeksworked18\":\"weeksworked22\"].head(3).T\n",
    "nls97.loc[:, \"colenroct15\":\"colenrfeb22\"].head(2).T\n",
    "\n",
    "# 显示有工资收入但无工作周数的个人\n",
    "nls97.loc[(nls97.weeksworked20==0) &\n",
    "   (nls97.wageincome20>0), \n",
    "  ['weeksworked20','wageincome20']]\n",
    "\n",
    "# 检查是否曾就读于四年制大学\n",
    "nls97.filter(like=\"colenr\").\\\n",
    "  apply(lambda x: x.str[0:1]=='3').\\\n",
    "  head(2).T\n",
    "nls97.filter(like=\"colenr\").\\\n",
    "  apply(lambda x: x.str[0:1]=='3').\\\n",
    "  any(axis=1).head(2)\n",
    "\n",
    "# 显示有研究生注册但无学士注册的个人\n",
    "nobach = nls97.loc[nls97.filter(like=\"colenr\").\\\n",
    "  apply(lambda x: x.str[0:1]=='4').\\\n",
    "  any(axis=1) & ~nls97.filter(like=\"colenr\").\\\n",
    "  apply(lambda x: x.str[0:1]=='3').\\\n",
    "  any(axis=1), \"colenrfeb97\":\"colenrfeb22\"]\n",
    "len(nobach)\n",
    "nobach.head(2).T\n",
    "\n",
    "# 显示拥有学士或以上学位但未就读四年制大学的个人\n",
    "nls97.highestdegree.value_counts().sort_index()\n",
    "no4yearenrollment = \\\n",
    "  nls97.loc[nls97.highestdegree.str[0:1].\\\n",
    "  isin(['4','5','6','7']) & \\\n",
    "  ~nls97.filter(like=\"colenr\").\\\n",
    "  apply(lambda x: x.str[0:1]=='3').\\\n",
    "  any(axis=1), \"colenrfeb97\":\"colenrfeb22\"]\n",
    "len(no4yearenrollment)\n",
    "no4yearenrollment.head(2).T\n",
    "\n",
    "# 显示工资收入高于或低于平均值三个标准差以上的个人\n",
    "highwages = \\\n",
    " nls97.loc[nls97.wageincome20 > \n",
    " nls97.wageincome20.mean()+ \\\n",
    " (nls97.wageincome20.std()*3),\n",
    " ['wageincome20']]\n",
    "highwages\n",
    "\n",
    "# 显示最近一年工作周数变化较大的个人\n",
    "workchanges = nls97.loc[~nls97.loc[:,\n",
    "  \"weeksworked16\":\"weeksworked20\"].mean(axis=1).\\\n",
    "  between(nls97.weeksworked21*0.5,\\\n",
    "  nls97.weeksworked21*2) \\\n",
    "  & ~nls97.weeksworked21.isnull(), \n",
    "  \"weeksworked16\":\"weeksworked21\"]\n",
    "len(workchanges)\n",
    "workchanges.head(6).T\n",
    "\n",
    "# 显示最高完成年级与最高学位不一致\n",
    "ltgrade12 = nls97.loc[nls97.highestgradecompleted<12, ['highestgradecompleted','highestdegree']]\n",
    "pd.crosstab(ltgrade12.highestgradecompleted, ltgrade12.highestdegree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "pd.set_option('display.width', 85)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 创建分析文件\n",
    "xvars = ['pop_density','median_age','gdp_per_capita']\n",
    "covidanalysis = covidtotals.loc[:,['total_cases_pm'] + xvars].dropna()\n",
    "\n",
    "covidanalysis.describe()\n",
    "\n",
    "# 拟合线性回归模型\n",
    "def getlm(df):\n",
    "  Y = df.total_cases_pm\n",
    "  X = df[['pop_density','median_age','gdp_per_capita']]\n",
    "  X = sm.add_constant(X)\n",
    "  return sm.OLS(Y, X).fit()\n",
    "\n",
    "lm = getlm(covidanalysis)\n",
    "lm.summary()\n",
    "\n",
    "# 确定对该模式有重大影响的国家\n",
    "influence = lm.get_influence().summary_frame()\n",
    "influence.loc[influence.cooks_d>0.5, ['cooks_d']]\n",
    "covidanalysis.loc[influence.cooks_d>0.5]\n",
    "\n",
    "# 做影响图\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sm.graphics.influence_plot(lm, ax = ax, alpha=5, criterion=\"cooks\")\n",
    "plt.show()\n",
    "\n",
    "# 显示没有异常值的模型\n",
    "covidanalysisminusoutliers = covidanalysis.loc[influence.cooks_d<0.5]\n",
    "\n",
    "lm = getlm(covidanalysisminusoutliers)\n",
    "lm.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN离群值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyod.models.knn import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.width', 53)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 创建分析变量的标准化数据集\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "analysisvars = ['location','total_cases_pm',\n",
    "  'total_deaths_pm','pop_density',\n",
    "  'median_age','gdp_per_capita']\n",
    "covidanalysis = covidtotals.loc[:, analysisvars].dropna()\n",
    "covidanalysisstand = standardizer.fit_transform(covidanalysis.iloc[:, 1:])\n",
    "\n",
    "# 运行 KNN 模型并生成异常分数\n",
    "clf_name = 'KNN'\n",
    "clf = KNN(contamination=0.1)\n",
    "clf.fit(covidanalysisstand)\n",
    "y_pred = clf.labels_\n",
    "y_scores = clf.decision_scores_\n",
    "\n",
    "# 显示模型的预测结果\n",
    "pred = pd.DataFrame(zip(y_pred, y_scores), \n",
    "  columns=['outlier','scores'], \n",
    "  index=covidanalysis.index)\n",
    "pred.sample(10, random_state=2)\n",
    "pred.outlier.value_counts()\n",
    "pred.groupby(['outlier'])[['scores']].agg(['min','median','max'])\n",
    "\n",
    "# 显示离群值的 covid 数据\n",
    "covidanalysis.join(pred).\\\n",
    "  loc[pred.outlier==1,\\\n",
    "  ['location','total_cases_pm',\n",
    "  'total_deaths_pm','scores']].\\\n",
    "  sort_values(['scores'],\n",
    "  ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 孤立森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.width', 58)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 创建标准化分析数据框架\n",
    "analysisvars = ['location','total_cases_pm','total_deaths_pm',\n",
    "  'pop_density','median_age','gdp_per_capita']\n",
    "standardizer = StandardScaler()\n",
    "covidtotals.isnull().sum()\n",
    "covidanalysis = covidtotals.loc[:, analysisvars].dropna()\n",
    "covidanalysisstand = standardizer.fit_transform(covidanalysis.iloc[:, 1:])\n",
    "\n",
    "# 运行孤立森林模型检测异常值\n",
    "clf=IsolationForest(n_estimators=100, \n",
    "  max_samples='auto', contamination=.1, \n",
    "  max_features=1.0, random_state=12345)\n",
    "clf.fit(covidanalysisstand)\n",
    "covidanalysis['anomaly'] = \\\n",
    "  clf.predict(covidanalysisstand)\n",
    "covidanalysis['scores'] = \\\n",
    "  clf.decision_function(covidanalysisstand)\n",
    "covidanalysis.anomaly.value_counts()\n",
    "\n",
    "# 查看异常值\n",
    "inlier, outlier = \\\n",
    "  covidanalysis.loc[covidanalysis.anomaly==1],\\\n",
    "  covidanalysis.loc[covidanalysis.anomaly==-1]\n",
    "analysisvars.append('scores')\n",
    "outlier[analysisvars].sort_values(['scores'])\n",
    "\n",
    "# 绘制离群值和异常值\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_title('Isolation Forest Anomaly Detection')\n",
    "ax.set_zlabel(\"Cases Per Million\")\n",
    "ax.set_xlabel(\"GDP Per Capita\")\n",
    "ax.set_ylabel(\"Median Age\")\n",
    "ax.scatter3D(inlier.gdp_per_capita, inlier.median_age, inlier.total_cases_pm, label=\"inliers\", c=\"blue\")\n",
    "ax.scatter3D(outlier.gdp_per_capita, outlier.median_age, outlier.total_cases_pm, label=\"outliers\", c=\"red\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别异常值-统计分析-孤立森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "# 离群值识别-孤立森林\n",
    "\n",
    "# 导入相应数据库客户端\n",
    "import mysql.connector as mdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# 设置目标 table 查询语句以提取数据\n",
    "targettable = \"name\"\n",
    "\n",
    "# 使用 mysql api 和 read_sql() 从 mysql 获取和加载数据\n",
    "host = \"pdccmysql\"\n",
    "user = \"pdccuser\"\n",
    "password = \"pdccpass\"\n",
    "database = \"pdccschema\"\n",
    "connmysql = mdb.connect(host=host,database=database,user=user,password=password)\n",
    "df = pd.read_sql_table(table_name=targettable,con=connmysql)    # 生成 DataFrame\n",
    "connmysql.close()\n",
    "\n",
    "# 将 DataFrame 中的一个或多个列设置为索引\n",
    "df.set_index(\"column1\", inplace=True)\n",
    "\n",
    "# 创建标准化分析数据框架-明确具有显著相关性的数据列\n",
    "analysisvars = ['column2','column3','column4','column5','column6','column7']\n",
    "# 去均值和方差归一化\n",
    "standardizer = StandardScaler()\n",
    "df.isnull().sum()\n",
    "dfanalysis = covidtotals.loc[:, analysisvars].dropna()\n",
    "dfanalysisstand = standardizer.fit_transform(df.iloc[:, 1:])\n",
    "\n",
    "# 运行孤立森林模型检测异常值\n",
    "clf=IsolationForest(n_estimators=100, \n",
    "  max_samples='auto', contamination=.1, \n",
    "  max_features=1.0, random_state=12345)\n",
    "clf.fit(dfanalysisstand)\n",
    "dfanalysis['anomaly'] = \\\n",
    "  clf.predict(dfanalysisstand)\n",
    "dfanalysis['scores'] = \\\n",
    "  clf.decision_function(dfanalysisstand)\n",
    "dfanalysis.anomaly.value_counts()\n",
    "\n",
    "# 输出异常值CSV\n",
    "inlier, outlier = \\\n",
    "  dfanalysis.loc[dfanalysis.anomaly==1],\\\n",
    "  dfanalysis.loc[dfanalysis.anomaly==-1]\n",
    "analysisvars.append('scores')\n",
    "outlier[analysisvars].sort_values(['scores'])\n",
    "outlier.to_csv('path/views/Outliers_name.csv')\n",
    "\n",
    "# 绘制离群值和异常值并保存为图片\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_title('Isolation Forest Anomaly Detection')\n",
    "ax.set_zlabel(\"Cases Per Million\")\n",
    "ax.set_xlabel(\"GDP Per Capita\")\n",
    "ax.set_ylabel(\"Median Age\")\n",
    "ax.scatter3D(inlier.gdp_per_capita, inlier.median_age, inlier.total_cases_pm, label=\"inliers\", c=\"blue\")\n",
    "ax.scatter3D(outlier.gdp_per_capita, outlier.median_age, outlier.total_cases_pm, label=\"outliers\", c=\"red\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"path/views/Outliers_name.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai.llm.openai import OpenAI\n",
    "from pandasai import SmartDataframe\n",
    "llm = OpenAI(api_token=\"Your API key\")\n",
    "\n",
    "pd.set_option('display.width', 70)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 220)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 加载数据帧并创建智能数据帧对象\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "\n",
    "covidtotalssdf = SmartDataframe(covidtotals, config={\"llm\": llm})\n",
    "\n",
    "# 运行一些查询\n",
    "covidtotalssdf.chat(\"Plot histogram of total cases per million\")\n",
    "covidtotalssdf.chat(\"Show boxplot of total cases per million\")\n",
    "covidtotalssdf.chat(\"regplot total_deaths_pm on total_cases_pm\")\n",
    "covidtotalssdf.chat(\"Show total cases per million 7 highest values and 7 lowest values of total cases per million sorted by total cases per million\")\n",
    "covidtotalssdf.chat(\"Show total cases per million for locations with highest total cases per million in each region\")\n",
    "covidtotalssdf.chat(\"Show total cases per million and total deaths per million for locationss with high total_cases_pm and low total_deaths_pm\")\n",
    "covidtotalssdf.chat(\"What variables are highly correlated with total cases\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
