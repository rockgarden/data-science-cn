{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN决策树\n",
    "\n",
    "KNN Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "\n",
    "from preprocfunc import OutlierTrans\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# load the land temperatures data\n",
    "un_income_gap = pd.read_csv(\"data/un_income_gap.csv\")\n",
    "un_income_gap.set_index('country', inplace=True)\n",
    "un_income_gap['incomeratio'] = \\\n",
    "  un_income_gap.femaleincomepercapita / \\\n",
    "    un_income_gap.maleincomepercapita\n",
    "un_income_gap['educratio'] = \\\n",
    "  un_income_gap.femaleyearseducation / \\\n",
    "     un_income_gap.maleyearseducation\n",
    "un_income_gap['laborforcepartratio'] = \\\n",
    "  un_income_gap.femalelaborforceparticipation / \\\n",
    "     un_income_gap.malelaborforceparticipation\n",
    "un_income_gap['humandevratio'] = \\\n",
    "  un_income_gap.femalehumandevelopment / \\\n",
    "     un_income_gap.malehumandevelopment\n",
    "un_income_gap.dropna(subset=['incomeratio'])\n",
    "\n",
    "num_cols = ['educratio','laborforcepartratio','humandevratio',\n",
    "  'genderinequality','maternalmortaility',\n",
    "  'adolescentbirthrate', 'femaleperparliament','incomepercapita']\n",
    "\n",
    "gap_sub = un_income_gap[['incomeratio'] + num_cols]\n",
    "\n",
    "gap_sub.head()\n",
    "\n",
    "gap_sub.\\\n",
    "  agg(['count','min','median','max']).T\n",
    "  \n",
    "# show a heatmap of correlations\n",
    "corrmatrix = gap_sub.corr(method=\"pearson\")\n",
    "corrmatrix\n",
    "\n",
    "sns.heatmap(corrmatrix, xticklabels=corrmatrix.columns,\n",
    "  yticklabels=corrmatrix.columns, cmap=\"coolwarm\")\n",
    "plt.title('Heat Map of Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "  \n",
    "# create training and testing DataFrames\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(gap_sub[num_cols],\\\n",
    "  gap_sub[['incomeratio']], test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# construct a pipeline with preprocessing, feature selection, and knn model\n",
    "knnreg = KNeighborsRegressor()\n",
    "\n",
    "feature_sel = SelectFromModel(LinearRegression(), threshold=\"0.8*mean\")\n",
    "\n",
    "pipe1 = make_pipeline(OutlierTrans(3), \\\n",
    "  SimpleImputer(strategy=\"median\"), StandardScaler(), \\\n",
    "  feature_sel, knnreg, memory=None)\n",
    "\n",
    "knnreg_params = {\n",
    " 'kneighborsregressor__n_neighbors': \\\n",
    "     np.arange(3, 21, 2),\n",
    " 'kneighborsregressor__metric': \\\n",
    "     ['euclidean','manhattan','minkowski']\n",
    "}\n",
    "\n",
    "# do a randmoized parameter search\n",
    "rs = RandomizedSearchCV(pipe1, knnreg_params, cv=4, n_iter=20, \\\n",
    "  scoring='neg_mean_absolute_error', random_state=1, error_score='raise')\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "selected = rs.best_estimator_['selectfrommodel'].get_support()\n",
    "np.array(num_cols)[selected]\n",
    "\n",
    "rs.best_estimator_['selectfrommodel'].\\\n",
    "  get_feature_names_out(np.array(num_cols))\n",
    "\n",
    "results = \\\n",
    "  pd.DataFrame(rs.cv_results_['mean_test_score'], \\\n",
    "    columns=['meanscore']).\\\n",
    "  join(pd.DataFrame(rs.cv_results_['params']), how=\"left\", on=None, validate=\"many_to_many\").\\\n",
    "  sort_values(['meanscore'], ascending=False)\n",
    "\n",
    "results.head(3).T\n",
    "\n",
    "# get predictions and residuals\n",
    "pred = rs.predict(X_test)\n",
    "\n",
    "preddf = pd.DataFrame(pred, columns=['prediction'],\n",
    "  index=X_test.index).join(X_test, how=\"left\", on=None, validate=\"many_to_many\").join(y_test, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "preddf['resid'] = preddf.incomeratio-preddf.prediction\n",
    "\n",
    "preddf.resid.agg(['mean','median','skew','kurtosis'])\n",
    "\n",
    "plt.hist(preddf.resid, color=\"blue\", bins=5)\n",
    "plt.axvline(preddf.resid.mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Histogram of Residuals for Income Ratio Model\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(preddf.prediction, preddf.resid, color=\"blue\")\n",
    "plt.axhline(0, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Scatterplot of Predictions and Residuals\")\n",
    "plt.xlabel(\"Predicted Income Ratio\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "preddf.loc[np.abs(preddf.resid)>=0.1,\n",
    "  ['incomeratio','prediction','resid','laborforcepartratio',\n",
    "  'humandevratio']].T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树回归\n",
    "\n",
    "decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "from preprocfunc import OutlierTrans\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# load the land temperatures data\n",
    "un_income_gap = pd.read_csv(\"data/un_income_gap.csv\")\n",
    "un_income_gap.set_index('country', inplace=True)\n",
    "un_income_gap['incomeratio'] = \\\n",
    "  un_income_gap.femaleincomepercapita / \\\n",
    "    un_income_gap.maleincomepercapita\n",
    "un_income_gap['educratio'] = \\\n",
    "  un_income_gap.femaleyearseducation / \\\n",
    "     un_income_gap.maleyearseducation\n",
    "un_income_gap['laborforcepartratio'] = \\\n",
    "  un_income_gap.femalelaborforceparticipation / \\\n",
    "     un_income_gap.malelaborforceparticipation\n",
    "un_income_gap['humandevratio'] = \\\n",
    "  un_income_gap.femalehumandevelopment / \\\n",
    "     un_income_gap.malehumandevelopment\n",
    "un_income_gap.dropna(subset=['incomeratio'], inplace=True)\n",
    "\n",
    "\n",
    "num_cols = ['educratio','laborforcepartratio','humandevratio',\n",
    "  'genderinequality','maternalmortaility',\n",
    "  'adolescentbirthrate', 'femaleperparliament','incomepercapita']\n",
    "\n",
    "gap_sub = un_income_gap[['incomeratio'] + num_cols]\n",
    "\n",
    "# create training and testing DataFrames\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(gap_sub[num_cols],\\\n",
    "  gap_sub[['incomeratio']], test_size=0.2, random_state=0)\n",
    "\n",
    "# construct a pipeline with preprocessing and knn model\n",
    "dtreg_example = DecisionTreeRegressor(min_samples_leaf=5,\n",
    "  max_depth=3)\n",
    "\n",
    "pipe0 = make_pipeline(OutlierTrans(3),\n",
    "  SimpleImputer(strategy=\"median\"))\n",
    "\n",
    "X_train_imp = pipe0.fit_transform(X_train)\n",
    "\n",
    "dtreg_example.fit(X_train_imp, y_train)\n",
    "\n",
    "plot_tree(dtreg_example, feature_names=X_train.columns,\n",
    "  label=\"root\", fontsize=10)\n",
    "\n",
    "# construct a decision tree model\n",
    "dtreg = DecisionTreeRegressor()\n",
    "\n",
    "feature_sel = SelectFromModel(LinearRegression(),\n",
    "  threshold=\"0.8*mean\")\n",
    "\n",
    "pipe1 = make_pipeline(OutlierTrans(3),\n",
    "  SimpleImputer(strategy=\"median\"),\n",
    "  feature_sel, dtreg)\n",
    "\n",
    "dtreg_params={\n",
    " \"decisiontreeregressor__max_depth\": np.arange(2, 20),\n",
    " \"decisiontreeregressor__min_samples_leaf\": np.arange(5, 11)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(pipe1, dtreg_params, cv=4, n_iter=20,\n",
    "  scoring='neg_mean_absolute_error', random_state=1)\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "# construct a random forest model\n",
    "rfreg = RandomForestRegressor()\n",
    "\n",
    "rfreg_params = {\n",
    " 'randomforestregressor__max_depth': np.arange(2, 20),\n",
    " 'randomforestregressor__max_features': ['auto', 'sqrt'],\n",
    " 'randomforestregressor__min_samples_leaf':  np.arange(5, 11)\n",
    "}\n",
    "\n",
    "pipe2 = make_pipeline(OutlierTrans(3), \n",
    "  SimpleImputer(strategy=\"median\"),\n",
    "  feature_sel, rfreg)\n",
    "\n",
    "rs = RandomizedSearchCV(pipe2, rfreg_params, cv=4, n_iter=20,\n",
    "  scoring='neg_mean_absolute_error', random_state=1)\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "# get predictions and residuals\n",
    "pred = rs.predict(X_test)\n",
    "\n",
    "\n",
    "preddf = pd.DataFrame(pred, columns=['prediction'],\n",
    "  index=X_test.index).join(X_test).join(y_test, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "preddf['resid'] = preddf.incomeratio-preddf.prediction\n",
    "\n",
    "\n",
    "plt.hist(preddf.resid, color=\"blue\", bins=5)\n",
    "plt.axvline(preddf.resid.mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Histogram of Residuals for Income Ratio\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(preddf.prediction, preddf.resid, color=\"blue\")\n",
    "plt.axhline(0, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Scatterplot of Predictions and Residuals\")\n",
    "plt.xlabel(\"Predicted Income Ratio\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "preddf.loc[np.abs(preddf.resid)>=0.12,\n",
    "  ['incomeratio','prediction','resid',\n",
    "  'laborforcepartratio', 'humandevratio']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度增强决策树\n",
    "\n",
    "gradient boosted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "from preprocfunc import OutlierTrans\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# load the land temperatures data\n",
    "housing = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "housing.set_index('id', inplace=True)\n",
    "\n",
    "num_cols = ['bedrooms','bathrooms','sqft_living','sqft_lot',\n",
    "  'floors','view','condition','sqft_above','sqft_basement',\n",
    "  'yr_built','yr_renovated','sqft_living15','sqft_lot15']\n",
    "cat_cols = ['waterfront']\n",
    "\n",
    "housing[['price'] + num_cols + cat_cols].\\\n",
    "  head(3).T\n",
    "\n",
    "housing[['price'] + num_cols].\\\n",
    "  agg(['count','min','median','max']).T\n",
    "  \n",
    "\n",
    "plt.hist(housing.price/1000)\n",
    "plt.title(\"Housing Price (in thousands)\")\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "housing['price_log'] = np.log(housing['price'])\n",
    "\n",
    "plt.hist(housing.price_log)\n",
    "plt.title(\"Housing Price Log\")\n",
    "plt.xlabel('Price Log')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "housing[['price','price_log']].agg(['kurtosis','skew'])\n",
    "\n",
    "# look at some correlations\n",
    "corrmatrix = housing[['price_log'] + num_cols].\\\n",
    "   corr(method=\"pearson\")\n",
    "\n",
    "sns.heatmap(corrmatrix, xticklabels=corrmatrix.columns,\n",
    "  yticklabels=corrmatrix.columns, cmap=\"coolwarm\")\n",
    "plt.title('Heat Map of Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# generate some summary statistics\n",
    "target = housing[['price_log']]\n",
    "features = housing[num_cols + cat_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(features,\\\n",
    "  target, test_size=0.2, random_state=0)\n",
    "      \n",
    "# setup pipelines for column transformation\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "standtrans = make_pipeline(OutlierTrans(2),\n",
    "  SimpleImputer(strategy=\"median\"),\n",
    "  MinMaxScaler())\n",
    "cattrans = make_pipeline(ohe)\n",
    "coltrans = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"stand\", standtrans, num_cols),\n",
    "    (\"cat\", cattrans, cat_cols)\n",
    "  ]\n",
    ")\n",
    "\n",
    "# construct a gradient boosted regressor\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "feature_sel = SelectFromModel(LinearRegression(),\n",
    "  threshold=\"0.6*mean\")\n",
    "\n",
    "gbr_params = {\n",
    " 'gradientboostingregressor__learning_rate': uniform(loc=0.01, scale=0.5),\n",
    " 'gradientboostingregressor__n_estimators': randint(500, 2000),\n",
    " 'gradientboostingregressor__max_depth': randint(2, 20),\n",
    " 'gradientboostingregressor__min_samples_leaf': randint(5, 11)\n",
    "}\n",
    "\n",
    "pipe1 = make_pipeline(coltrans, feature_sel, gbr)\n",
    "\n",
    "rs1 = RandomizedSearchCV(pipe1, gbr_params, cv=5, n_iter=20,\n",
    "  scoring='neg_mean_squared_error', n_jobs=-1, random_state=0)\n",
    "\n",
    "rs1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs1.best_params_\n",
    "rs1.best_score_\n",
    "\n",
    "y_test.mean()\n",
    "\n",
    "print(\"fit time: %.3f, score time: %.3f\"  %\n",
    "  (np.mean(rs1.cv_results_['mean_fit_time']),\\\n",
    "  np.mean(rs1.cv_results_['mean_score_time'])))\n",
    "\n",
    "# construct an XGBoost model    \n",
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb_params = {\n",
    " 'xgbregressor__learning_rate': uniform(loc=0.01, scale=0.5),\n",
    " 'xgbregressor__n_estimators': randint(500, 2000),\n",
    " 'xgbregressor__max_depth': randint(2, 20)\n",
    "}\n",
    "\n",
    "pipe2 = make_pipeline(coltrans, feature_sel, xgb)\n",
    "\n",
    "rs2 = RandomizedSearchCV(pipe2, xgb_params, cv=5, n_iter=20,\n",
    "  scoring='neg_mean_squared_error', n_jobs=-1, random_state=0)\n",
    "\n",
    "rs2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs2.best_params_\n",
    "rs2.best_score_\n",
    "\n",
    "print(\"fit time: %.3f, score time: %.3f\"  %\n",
    "  (np.mean(rs2.cv_results_['mean_fit_time']),\\\n",
    "  np.mean(rs2.cv_results_['mean_score_time'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度提升决策树\n",
    "\n",
    "gradient boosted decision treekeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "from preprocfunc import OutlierTrans\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# load the land temperatures data\n",
    "fftaxrate14 = pd.read_csv(\"data/fossilfueltaxrate14.csv\")\n",
    "fftaxrate14.set_index('countrycode', inplace=True)\n",
    "fftaxrate14.info()\n",
    "\n",
    "# setup the features and target\n",
    "num_cols = ['fuel_income_dependence','national_income_per_cap',\n",
    "  'VAT_Rate',  'gov_debt_per_gdp','polity','goveffect',\n",
    "  'democracy_index']\n",
    "dummy_cols = ['democracy_polity','autocracy_polity','democracy',\n",
    "  'nat_oil_comp','nat_oil_comp_state']\n",
    "spec_cols = ['motorization_rate']\n",
    "\n",
    "# generate some summary statistics\n",
    "fftaxrate14[['gas_tax_imp'] + num_cols + spec_cols].\\\n",
    "  agg(['count','min','median','max']).T\n",
    "fftaxrate14[dummy_cols].apply(pd.value_counts, normalize=True).T\n",
    "\n",
    "target = fftaxrate14[['gas_tax_imp']]\n",
    "features = fftaxrate14[num_cols + dummy_cols + spec_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(features,\\\n",
    "  target, test_size=0.2, random_state=0)\n",
    "      \n",
    "# setup pipelines for column transformation\n",
    "standtrans = make_pipeline(OutlierTrans(2), SimpleImputer(strategy=\"median\"))\n",
    "cattrans = make_pipeline(SimpleImputer(strategy=\"most_frequent\"))\n",
    "spectrans = make_pipeline(OutlierTrans(2))\n",
    "coltrans = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"stand\", standtrans, num_cols),\n",
    "    (\"cat\", cattrans, dummy_cols),\n",
    "    (\"spec\", spectrans, spec_cols)\n",
    "  ]\n",
    ")\n",
    "\n",
    "# construct a decision tree model\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "feature_sel = SelectFromModel(LinearRegression(),\n",
    "  threshold=\"0.8*mean\")\n",
    "\n",
    "gbr_params = {\n",
    " 'gradientboostingregressor__learning_rate': uniform(loc=0.1, scale=0.5),\n",
    " 'gradientboostingregressor__n_estimators': randint(100, 1000),\n",
    " 'gradientboostingregressor__max_depth': np.arange(2, 20),\n",
    " 'gradientboostingregressor__min_samples_leaf': np.arange(5, 11)\n",
    "}\n",
    "\n",
    "pipe1 = make_pipeline(OutlierTrans(3),\n",
    "  SimpleImputer(strategy=\"median\"),\n",
    "  feature_sel, gbr)\n",
    "\n",
    "rs = RandomizedSearchCV(pipe1, gbr_params, cv=4, n_iter=20,\n",
    "  scoring='neg_mean_absolute_error', random_state=1)\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "# get predictions and residuals\n",
    "pred = rs.predict(X_test)\n",
    "\n",
    "\n",
    "preddf = pd.DataFrame(pred, columns=['prediction'],\n",
    "  index=X_test.index).join(X_test).join(y_test, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "preddf['resid'] = preddf.incomeratio-preddf.prediction\n",
    "\n",
    "\n",
    "plt.hist(preddf.resid, color=\"blue\", bins=5)\n",
    "plt.axvline(preddf.resid.mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Histogram of Residuals for Income Ratio\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(preddf.prediction, preddf.resid, color=\"blue\")\n",
    "plt.axhline(0, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Scatterplot of Predictions and Residuals\")\n",
    "plt.xlabel(\"Predicted Income Ratio\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "preddf.loc[np.abs(preddf.resid)>=0.12,\n",
    "  ['incomeratio','prediction','resid',\n",
    "  'laborforcepartratio', 'humandevratio']].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
