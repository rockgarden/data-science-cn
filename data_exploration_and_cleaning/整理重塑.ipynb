{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#　删除重复项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 62)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "covidcases = pd.read_csv(\"data/covidcases.csv\")\n",
    "\n",
    "# 为每日案例、累积列和人口统计列创建列表\n",
    "dailyvars = ['casedate','new_cases','new_deaths']\n",
    "totvars = ['location','total_cases','total_deaths']\n",
    "\n",
    "demovars = ['population','population_density',\n",
    "  'median_age','gdp_per_capita',\n",
    "  'hospital_beds_per_thousand','region']\n",
    "covidcases[dailyvars + totvars + demovars].head(2).T\n",
    "\n",
    "# 创建每日数据帧\n",
    "coviddaily = covidcases[['location'] + dailyvars]\n",
    "coviddaily.shape\n",
    "coviddaily.head()\n",
    "\n",
    "# 为每个国家/地区选择一行\n",
    "covidcases.location.nunique()\n",
    "coviddemo = \\\n",
    "  covidcases[['casedate'] + totvars + demovars].\\\n",
    "  sort_values(['location','casedate']).\\\n",
    "  drop_duplicates(['location'], keep='last').\\\n",
    "  rename(columns={'casedate':'lastdate'})\n",
    "\n",
    "coviddemo.shape\n",
    "coviddemo.head(2).T\n",
    "\n",
    "# 每组的总和值\n",
    "covidtotals = covidcases.groupby(['location'],\n",
    "  as_index=False).\\\n",
    "  agg({'new_cases':'sum','new_deaths':'sum',\n",
    "    'median_age':'last','gdp_per_capita':'last',\n",
    "    'region':'last','casedate':'last',\n",
    "    'population':'last'}).\\\n",
    "  rename(columns={'new_cases':'total_cases',\n",
    "    'new_deaths':'total_deaths',\n",
    "    'casedate':'lastdate'})\n",
    "  \n",
    "covidtotals.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多对多重塑\n",
    "\n",
    "many to many reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 56)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "cma = pd.read_csv(\"data/cmacollections.csv\")\n",
    "cma['category'] = cma.category.str.strip().str[0:15]\n",
    "cma['title'] = cma.title.str.strip().str[0:30]\n",
    "\n",
    "# show the cma collections data\n",
    "cma.shape\n",
    "\n",
    "cma.head(4).T\n",
    "cma.itemid.nunique()\n",
    "\n",
    "cma.drop_duplicates(['itemid','citation']).\\\n",
    "  itemid.count()\n",
    "cma.drop_duplicates(['itemid','creatorid']).\\\n",
    "  itemid.count()\n",
    "\n",
    "# show a collection item with duplicated citations and creators\n",
    "cma.set_index(['itemid'], inplace=True)\n",
    "cma.loc[124733, ['title','citation',\n",
    "  'creation_date','creator','birth_year']].head(6)\n",
    "\n",
    "# create a collections data frame\n",
    "collectionsvars = \\\n",
    "  ['title','category','creation_date']\n",
    "cmacollections = cma[collectionsvars].\\\n",
    "  reset_index().\\\n",
    "  drop_duplicates(['itemid']).\\\n",
    "  set_index(['itemid'])\n",
    "cmacollections.shape\n",
    "cmacollections.head()\n",
    "cmacollections.loc[124733]\n",
    "\n",
    "# create a citations data frame\n",
    "cmacitations = cma[['citation']].\\\n",
    "  reset_index().\\\n",
    "  drop_duplicates(['itemid','citation']).\\\n",
    "  set_index(['itemid'])\n",
    "cmacitations.loc[124733]\n",
    "\n",
    "# create a creators data frame\n",
    "creatorsvars = \\\n",
    "  ['creator','birth_year','death_year']\n",
    "cmacreators = cma[creatorsvars].\\\n",
    "  reset_index().\\\n",
    "  drop_duplicates(['itemid','creator']).\\\n",
    "  set_index(['itemid'])\n",
    "cmacreators.loc[124733]\n",
    "\n",
    "# count the number of collection items with a creator born after 1950\n",
    "cmacreators['birth_year'] = \\\n",
    "  cmacreators.birth_year.str.\\\n",
    "  findall(\"\\d+\").str[0].astype(float)\n",
    "    \n",
    "youngartists = \\\n",
    "  cmacreators.loc[cmacreators.birth_year>1950,\n",
    "  ['creator']].assign(creatorbornafter1950='Y')\n",
    "youngartists.shape[0]==youngartists.index.nunique()\n",
    "youngartists\n",
    "\n",
    "cmacollections = \\\n",
    "  pd.merge(cmacollections, youngartists, \n",
    "  left_on=['itemid'], right_on=['itemid'], how='left', validate=\"many_to_many\")\n",
    "cmacollections.fillna({'creatorbornafter1950':'N'}, inplace=True)\n",
    "cmacollections.shape\n",
    "cmacollections.creatorbornafter1950.value_counts()\n",
    "\n",
    "youngartists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 堆栈熔化\n",
    "\n",
    "stack_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "\n",
    "# view some of the weeks worked values\n",
    "nls97.set_index(['originalid'], inplace=True)\n",
    "weeksworkedcols = ['weeksworked17','weeksworked18',\n",
    "  'weeksworked19','weeksworked20','weeksworked21']\n",
    "\n",
    "nls97.loc[[2,3],weeksworkedcols].T\n",
    "nls97.shape\n",
    "\n",
    "# use stack to convert data from wide to long\n",
    "weeksworked = nls97[weeksworkedcols].\\\n",
    "  stack().\\\n",
    "  reset_index().\\\n",
    "  rename(columns={'level_1':'year',0:'weeksworked'})\n",
    "\n",
    "pd.__version__\n",
    "\n",
    "weeksworked.loc[weeksworked.originalid.isin([2,3])]\n",
    "\n",
    "# Fix the year values\n",
    "weeksworked['year'] = \\\n",
    "  weeksworked.year.str[-2:].astype(int)+2000\n",
    "weeksworked.loc[weeksworked.originalid.isin([2,3])]\n",
    "weeksworked.shape\n",
    "\n",
    "# use melt to transform data from wide to long\n",
    "weeksworked = nls97.reset_index().\\\n",
    "  loc[:,['originalid'] + weeksworkedcols].\\\n",
    "  melt(id_vars=['originalid'],\n",
    "  value_vars=weeksworkedcols,\n",
    "  var_name='year', value_name='weeksworked')\n",
    "\n",
    "weeksworked['year'] = \\\n",
    "  weeksworked.year.str[-2:].astype(int)+2000\n",
    "weeksworked.set_index(['originalid'], inplace=True)\n",
    "weeksworked.loc[[2,3]]\n",
    "\n",
    "\n",
    "nls97.head(2).T\n",
    "\n",
    "# reshape more columns with melt\n",
    "colenrcols = \\\n",
    "  ['colenroct17','colenroct18','colenroct19',\n",
    "  'colenroct20','colenroct21']\n",
    "colenr = nls97.reset_index().\\\n",
    "  loc[:,['originalid'] + colenrcols].\\\n",
    "  melt(id_vars=['originalid'], value_vars=colenrcols,\n",
    "    var_name='year', value_name='colenr')\n",
    "\n",
    "colenr['year'] = colenr.year.str[-2:].astype(int)+2000\n",
    "colenr.set_index(['originalid'], inplace=True)\n",
    "colenr.loc[[2,3]]\n",
    "\n",
    "# merge the weeks worked and enrollment data\n",
    "workschool = \\\n",
    "  pd.merge(weeksworked, colenr, on=['originalid','year'], how=\"inner\", validate=\"many_to_many\")\n",
    "workschool.shape\n",
    "\n",
    "#workschool.set_index(['originalid'], inplace=True)\n",
    "workschool.loc[[2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 宽至长\n",
    "\n",
    "wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index('personid', inplace=True)\n",
    "\n",
    "# view some of the weeks worked and college enrollment data\n",
    "weeksworkedcols = ['weeksworked17','weeksworked18',\n",
    "  'weeksworked19','weeksworked20','weeksworked21']\n",
    "\n",
    "colenrcols = ['colenroct17','colenroct18',\n",
    "   'colenroct19','colenroct20','colenroct21']\n",
    "\n",
    "nls97.loc[nls97.originalid.isin([2,3]),\n",
    "  ['originalid'] + weeksworkedcols + colenrcols].T\n",
    "\n",
    "# run the wide_to_long function\n",
    "workschool = pd.wide_to_long(nls97[['originalid'] \n",
    "  + weeksworkedcols + colenrcols], \n",
    "  stubnames=['weeksworked','colenroct'], \n",
    "  i=['originalid'], j='year').reset_index()\n",
    "workschool['year'] = workschool.year+2000\n",
    "workschool = workschool.\\\n",
    "  sort_values(['originalid','year'])\n",
    "workschool.set_index(['originalid'], inplace=True)\n",
    "workschool.loc[[2,3]]\n",
    "\n",
    "# run the melt with unaligned suffixes\n",
    "weeksworkedcols = ['weeksworked16','weeksworked18',\n",
    "  'weeksworked19','weeksworked20','weeksworked21']\n",
    "workschool = pd.wide_to_long(nls97[['originalid']\n",
    "  + weeksworkedcols + colenrcols], \n",
    "  stubnames=['weeksworked','colenroct'], \n",
    "  i=['originalid'], j='year').reset_index()\n",
    "workschool['year'] = workschool.year+2000\n",
    "workschool = workschool.sort_values(['originalid','year'])\n",
    "workschool.set_index(['originalid'], inplace=True)\n",
    "workschool.loc[[2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卸载支点\n",
    "\n",
    "unstack pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "weeksworkedstacked = pd.read_pickle(\"data/nlsweeksworkedstacked.pkl\")\n",
    "workschoolmelted = pd.read_pickle(\"data/nlsworkschoolmelted.pkl\")\n",
    "\n",
    "# view the stacked weeks worked data\n",
    "weeksworkedstacked.head(10)\n",
    "weeksworkedstacked.index\n",
    "\n",
    "# use stack to convert from long to wide\n",
    "weeksworked = weeksworkedstacked.unstack()\n",
    "weeksworked.head(10)\n",
    "\n",
    "# use pivot to convert from long to wide\n",
    "workschoolmelted.loc[workschoolmelted.originalid.isin([1,2])].sort_values(['originalid','year'])\n",
    "workschool = workschoolmelted.pivot(index='originalid', columns='year', values=['weeksworked','colenroct']).reset_index()\n",
    "workschool.columns = workschool.columns.map('{0[0]}{0[1]}'.format)\n",
    "workschool.loc[workschool.originalid.isin([1,2])].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卸载支点b\n",
    "\n",
    "unstack pivotb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(['originalid'], inplace=True)\n",
    "\n",
    "# stack the data again\n",
    "weeksworkedcols = ['weeksworked17','weeksworked18',\n",
    "  'weeksworked19','weeksworked20','weeksworked21']\n",
    "\n",
    "weeksworkedstacked = nls97[weeksworkedcols].\\\n",
    "  stack()\n",
    "weeksworkedstacked.loc[[2,3]]\n",
    "\n",
    "pd.__version__\n",
    "\n",
    "# melt the data again\n",
    "weeksworkedmelted = nls97.reset_index().\\\n",
    "  loc[:,['originalid'] + weeksworkedcols].\\\n",
    "  melt(id_vars=['originalid'], \n",
    "  value_vars=weeksworkedcols,\n",
    "  var_name='year', value_name='weeksworked')\n",
    "weeksworkedmelted.loc[weeksworkedmelted.\\\n",
    "  originalid.isin([2,3])].\\\n",
    "  sort_values(['originalid','year'])\n",
    "\n",
    "# use stack to convert from long to wide\n",
    "weeksworked = weeksworkedstacked.unstack()\n",
    "weeksworked.loc[[2,3]].T\n",
    "\n",
    "# use pivot to convert from long to wide\n",
    "weeksworked = weeksworkedmelted.\\\n",
    "  pivot(index='originalid',\n",
    "  columns='year', values=['weeksworked']).\\\n",
    "  reset_index()\n",
    "weeksworked.columns = ['originalid'] + \\\n",
    "  [col[1] for col in weeksworked.columns[1:]]\n",
    "weeksworked.loc[weeksworked.originalid.isin([2,3])].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
