{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为分类选择特征\n",
    "\n",
    "selecting features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>119.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>108.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>96.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satmath</td>\n",
       "      <td>84.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>77.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>60.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>37.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>29.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>22.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender_Female</td>\n",
       "      <td>15.098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature   score\n",
       "5       gpaoverall 119.471\n",
       "3       gpaenglish 108.006\n",
       "2       gpascience  96.824\n",
       "1          satmath  84.901\n",
       "0        satverbal  77.363\n",
       "4          gpamath  60.930\n",
       "7  fatherhighgrade  37.481\n",
       "6  motherhighgrade  29.377\n",
       "8     parentincome  22.266\n",
       "9    gender_Female  15.098"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest,\\\n",
    "  mutual_info_classif, f_classif\n",
    "\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['gender','satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# 将 NLS 数据分为训练数据集和测试数据集\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "\n",
    "# 对性别特征进行编码，并对其他特征进行缩放\n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "X_train_enc = ohe.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.fit_transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "# 利用相互(mutual)信息选择预测大学毕业的 5 个最佳特征\n",
    "ksel = SelectKBest(score_func=mutual_info_classif, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[ksel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'score': ksel.scores_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','score']).\\\n",
    "   sort_values(['score'], ascending=False)\n",
    "X_train_analysis = X_train_enc[selcols]\n",
    "X_train_analysis.dtypes\n",
    "\n",
    "# 利用方差分析(ANOVA)选择预测大学毕业的 5 个最佳特征\n",
    "ksel = SelectKBest(score_func=f_classif, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[ksel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'score': ksel.scores_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','score']).\\\n",
    "   sort_values(['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为回归选择特征\n",
    "\n",
    "selecting features for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satmath</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>completedba</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  score\n",
       "1           satmath  0.101\n",
       "10      gender_Male  0.074\n",
       "7   fatherhighgrade  0.047\n",
       "2        gpascience  0.044\n",
       "9       completedba  0.044\n",
       "4           gpamath  0.016\n",
       "8      parentincome  0.015\n",
       "6   motherhighgrade  0.012\n",
       "0         satverbal  0.000\n",
       "3        gpaenglish  0.000\n",
       "5        gpaoverall  0.000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,\\\n",
    "  mutual_info_regression\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97wages = pd.read_csv(\"data/nls97wages.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome','completedba']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97wages[feature_cols],\\\n",
    "  nls97wages[['wageincome']], test_size=0.3, random_state=0)\n",
    "      \n",
    "# 对数据进行编码和缩放\n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "X_train_enc = ohe.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.fit_transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Male']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "y_train = \\\n",
    "  pd.DataFrame(scaler.fit_transform(y_train),\n",
    "  columns=['wageincome'], index=y_train.index)\n",
    "\n",
    "# 选择预测工资收入的 5 个最佳功能\n",
    "ksel = SelectKBest(score_func=f_regression, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[ksel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'score': ksel.scores_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','score']).\\\n",
    "   sort_values(['score'], ascending=False)\n",
    "\n",
    "# 利用交互(mutual)信息选出 5 个最佳特征\n",
    "from functools import partial\n",
    "ksel = SelectKBest(score_func=\\\n",
    "  partial(mutual_info_regression, random_state=0),\n",
    "  k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[ksel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'score': ksel.scores_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','score']).\\\n",
    "   sort_values(['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向前向后选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "\n",
    "# encode the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "X_train_enc = ohe.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.fit_transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs = SequentialFeatureSelector(rfc, k_features=5,\n",
    "  forward=True, floating=False, verbose=2,\n",
    "  scoring='accuracy', cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[list(sfs.k_feature_idx_)]\n",
    "selcols\n",
    "\n",
    "# Build step forward feature selection\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "sfs = SequentialFeatureSelector(rfc, k_features=5,\n",
    "  forward=False, floating=False, verbose=2,\n",
    "  scoring='accuracy', cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[list(sfs.k_feature_idx_)]\n",
    "selcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exhausive backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "\n",
    "# encode the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']])\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Female']])\n",
    "\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, \n",
    "  n_jobs=-1, random_state=0)\n",
    "\n",
    "# Build exhaustive feature selection\n",
    "efs = ExhaustiveFeatureSelector(rfc, max_features=5,\n",
    "  min_features=1, scoring='accuracy', \n",
    "  print_progress=True, cv=5)\n",
    "\n",
    "# Perform EFS\n",
    "efs.fit(X_train_enc, y_train.values.ravel())\n",
    "efs.best_feature_names_\n",
    "\n",
    "# evaluate the accuracy of the random forest classifier model\n",
    "X_train_efs = efs.transform(X_train_enc)\n",
    "X_test_efs = efs.transform(X_test_enc)\n",
    "\n",
    "rfc.fit(X_train_efs, y_train.values.ravel())\n",
    "y_pred = rfc.predict(X_test_efs)\n",
    "\n",
    "confusion = pd.DataFrame(y_pred, columns=['pred'],\n",
    "  index=y_test.index).\\\n",
    "  join(y_test)\n",
    "confusion.loc[confusion.pred==confusion.completedba].shape[0]\\\n",
    "  /confusion.shape[0]\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# build logistic classifier and redo the feature selection\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "efs = ExhaustiveFeatureSelector(lr, max_features=5,\n",
    "  min_features=1, scoring='accuracy', \n",
    "  print_progress=True, cv=5)\n",
    "efs.fit(X_train_enc, y_train.values.ravel())\n",
    "efs.best_feature_names_\n",
    "\n",
    "\n",
    "# evaluate the accuracy of the logistic model\n",
    "X_train_efs = efs.transform(X_train_enc)\n",
    "X_test_efs = efs.transform(X_test_enc)\n",
    "\n",
    "lr.fit(X_train_efs, y_train.values.ravel())\n",
    "y_pred = lr.predict(X_test_efs)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE 回归\n",
    "\n",
    "rfe regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97wages = pd.read_csv(\"data/nls97wages.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome','gender','completedba']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97wages[feature_cols],\\\n",
    "  nls97wages[['weeklywage']], test_size=0.3, random_state=0)\n",
    "      \n",
    "# standardize and scale the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = feature_cols[:-2]\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Male','completedba']])\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Male','completedba']])\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train, y_test = \\\n",
    "  pd.DataFrame(scaler.transform(y_train),\n",
    "  columns=['weeklywage'], index=y_train.index),\\\n",
    "  pd.DataFrame(scaler.transform(y_test),\n",
    "  columns=['weeklywage'], index=y_test.index)\n",
    "\n",
    "\n",
    "# use decision trees for recursive feature elimination\n",
    "rfr = RandomForestRegressor(max_depth=2)\n",
    "\n",
    "treesel = RFE(estimator=rfr, n_features_to_select=5)\n",
    "treesel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[treesel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'ranking': treesel.ranking_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','ranking']).\\\n",
    "   sort_values(['ranking'], ascending=True)\n",
    "   \n",
    "rfr.fit(treesel.transform(X_train_enc), y_train.values.ravel())\n",
    "rfr.score(treesel.transform(X_train_enc), y_train.values.ravel())\n",
    "rfr.score(treesel.transform(X_test_enc), y_test)\n",
    "\n",
    "\n",
    "# use linear regression for recursive feature elimination\n",
    "lr = LinearRegression()\n",
    "\n",
    "lrsel = RFE(estimator=lr, n_features_to_select=5)\n",
    "lrsel.fit(X_train_enc, y_train)\n",
    "selcols = X_train_enc.columns[lrsel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'ranking': lrsel.ranking_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','ranking']).\\\n",
    "   sort_values(['ranking'], ascending=True)\n",
    "   \n",
    "lr.fit(lrsel.transform(X_train_enc), y_train)\n",
    "lr.score(lrsel.transform(X_train_enc), y_train)\n",
    "lr.score(lrsel.transform(X_test_enc), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "\n",
    "# encode the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Female']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, \n",
    "  n_jobs=-1, random_state=0)\n",
    "\n",
    "# Build exhaustive feature selection\n",
    "treesel = RFE(estimator=rfc, n_features_to_select=5)\n",
    "treesel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[treesel.get_support()]\n",
    "selcols\n",
    "pd.DataFrame({'ranking': treesel.ranking_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','ranking']).\\\n",
    "   sort_values(['ranking'], ascending=True)\n",
    "   \n",
    "# evaluate the accuracy of the random forest classifier model\n",
    "rfc.fit(treesel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = rfc.predict(treesel.transform(X_test_enc))\n",
    "\n",
    "confusion = pd.DataFrame(y_pred, columns=['pred'],\n",
    "  index=y_test.index).\\\n",
    "  join(y_test, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "confusion.loc[confusion.pred==confusion.completedba].shape[0]\\\n",
    "  /confusion.shape[0]\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boruta 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "\n",
    "# encode the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']])\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Female']])\n",
    "\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, \n",
    "  n_jobs=-1, random_state=0)\n",
    "\n",
    "# Build exhaustive feature selection\n",
    "borsel = BorutaPy(rfc, random_state=0, verbose=2)\n",
    "borsel.fit(X_train_enc.values, y_train.values.ravel())\n",
    "\n",
    "selcols = X_train_enc.columns[borsel.support_]\n",
    "selcols\n",
    "pd.DataFrame({'ranking': borsel.ranking_,\n",
    "  'feature': X_train_enc.columns},\n",
    "   columns=['feature','ranking']).\\\n",
    "   sort_values(['ranking'], ascending=True)\n",
    "   \n",
    "# evaluate the accuracy of the random forest classifier model\n",
    "rfc.fit(borsel.transform(X_train_enc.values), y_train.values.ravel())\n",
    "y_pred = rfc.predict(borsel.transform(X_test_enc.values))\n",
    "\n",
    "confusion = pd.DataFrame(y_pred, columns=['pred'],\n",
    "  index=y_test.index).\\\n",
    "  join(y_test)\n",
    "confusion.loc[confusion.pred==confusion.completedba].shape[0]\\\n",
    "  /confusion.shape[0]\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 规范化\n",
    "\n",
    "regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy, and matplotlib\n",
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender','motherhighgrade',\n",
    "  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3, random_state=0)\n",
    "      \n",
    "# do one hot encoding and scaling\n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']])\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Female']])\n",
    "\n",
    "# logistic regression for feature importance\n",
    "lr = LogisticRegression(C=1, penalty=\"l1\", solver='liblinear')\n",
    "regsel = SelectFromModel(lr, max_features=5)\n",
    "regsel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[regsel.get_support()]\n",
    "selcols\n",
    "\n",
    "lr.fit(regsel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = lr.predict(regsel.transform(X_test_enc))\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# random forest classification for feature importance\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, \n",
    "  n_jobs=-1, random_state=0)\n",
    "\n",
    "rfcsel = SelectFromModel(rfc, max_features=5)\n",
    "rfcsel.fit(X_train_enc, y_train.values.ravel())\n",
    "selcols = X_train_enc.columns[rfcsel.get_support()]\n",
    "selcols\n",
    "\n",
    "rfc.fit(rfcsel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = rfc.predict(rfcsel.transform(X_test_enc))\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.width', 75)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# load the NLS data\n",
    "nls97compba = pd.read_csv(\"data/nls97compba.csv\")\n",
    "\n",
    "feature_cols = ['satverbal','satmath','gpascience',\n",
    "  'gpaenglish','gpamath','gpaoverall','gender',\n",
    "  'motherhighgrade',  'fatherhighgrade','parentincome']\n",
    "\n",
    "# separate NLS data into train and test datasets\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(nls97compba[feature_cols],\\\n",
    "  nls97compba[['completedba']], test_size=0.3,\n",
    "  random_state=0)\n",
    "\n",
    "# encode the data      \n",
    "ohe = OneHotEncoder(drop_last=True, variables=['gender'])\n",
    "ohe.fit(X_train)\n",
    "X_train_enc, X_test_enc = \\\n",
    "  ohe.transform(X_train), ohe.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:,:-1].columns\n",
    "scaler.fit(X_train_enc[standcols])\n",
    "X_train_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_train_enc[standcols]),\n",
    "  columns=standcols, index=X_train_enc.index).\\\n",
    "  join(X_train_enc[['gender_Female']])\n",
    "X_test_enc = \\\n",
    "  pd.DataFrame(scaler.transform(X_test_enc[standcols]),\n",
    "  columns=standcols, index=X_test_enc.index).\\\n",
    "  join(X_test_enc[['gender_Female']])\n",
    "\n",
    "\n",
    "# instantiate a pca object and fit the model\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train_enc)\n",
    "\n",
    "# take a closer look at the components\n",
    "pd.DataFrame(pca.components_,\n",
    "  columns=X_train_enc.columns).T\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# create numpy arrays transformed values based on components\n",
    "X_train_pca = pca.transform(X_train_enc)\n",
    "X_train_pca.shape\n",
    "np.round(X_train_pca[0:6],2)\n",
    "X_test_pca = pca.transform(X_test_enc)\n",
    "\n",
    "# evaluate the accuracy of the random forest classifier model\n",
    "rfc = RandomForestClassifier(n_estimators=100, \n",
    "  max_depth=2, n_jobs=-1, random_state=0)\n",
    "\n",
    "rfc.fit(X_train_pca, y_train.values.ravel())\n",
    "y_pred = rfc.predict(X_test_pca)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
