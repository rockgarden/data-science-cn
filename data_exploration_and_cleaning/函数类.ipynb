{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初探\n",
    "\n",
    "Functions Classes\n",
    "\n",
    "vscode 编辑 settings.json，引入外部类：\n",
    "\n",
    "```json\n",
    "    \"python.analysis.extraPaths\": [\n",
    "        \"./data-cleaning/II/12.FunctionsClasses/helperfunctions\"\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index('personid', inplace=True)\n",
    "\n",
    "# 导入 basicdescriptives 模块\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import basicdescriptives as bd\n",
    "\n",
    "pd.set_option('display.width', 64)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# 初步了解 NLS 数据\n",
    "dfinfo = bd.getfirstlook(nls97)\n",
    "bd.displaydict(dfinfo)\n",
    "\n",
    "# 向 nrows 和 uniqueid 参数传递值\n",
    "dfinfo = bd.getfirstlook(nls97,2,'originalid')\n",
    "bd.displaydict(dfinfo)\n",
    "\n",
    "# 处理部分字典键和值\n",
    "dfinfo['nrows']\n",
    "dfinfo['dtypes']\n",
    "dfinfo['nrows'] == dfinfo['uniqueids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index('personid', inplace=True)\n",
    "\n",
    "# 导入 basicdescriptives \n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import basicdescriptives as bd\n",
    "import importlib\n",
    "importlib.reload(bd)\n",
    "\n",
    "pd.set_option('display.width', 80)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# 显示连续变量的汇总统计\n",
    "bd.gettots(nls97[['satverbal','satmath']]).T\n",
    "bd.gettots(nls97.filter(like=\"weeksworked\"))\n",
    "\n",
    "# 计算每列和每行的缺失数\n",
    "missingsbycols, missingsbyrows = \\\n",
    "  bd.getmissings(nls97[['weeksworked20',\n",
    "  'weeksworked21']], True)\n",
    "missingsbycols\n",
    "missingsbyrows\n",
    "missingsbycols, missingsbyrows = \\\n",
    "  bd.getmissings(nls97[['weeksworked20',\n",
    "  'weeksworked21']])\n",
    "missingsbyrows\n",
    "\n",
    "# 对分类列进行频率计算\n",
    "nls97.loc[:, nls97.dtypes == 'object'] = \\\n",
    "  nls97.select_dtypes(['object']). \\\n",
    "  apply(lambda x: x.astype('category'))\n",
    "bd.makefreqs(nls97, \"views/nlsfreqs.txt\")\n",
    "\n",
    "# 按组进行计数和百分比计算\n",
    "bd.getcnts(nls97, \n",
    "  ['maritalstatus','colenroct00'])\n",
    "bd.getcnts(nls97, \n",
    "  ['maritalstatus','colenroct00'],\n",
    "  \"colenroct00.str[0:1]=='1'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index('personid', inplace=True)\n",
    "covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n",
    "\n",
    "# 导入 outliers\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import outliers as ol\n",
    "import importlib\n",
    "importlib.reload(ol)\n",
    "pd.set_option('display.width', 72)\n",
    "pd.set_option('display.max_columns', 5)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# 获取变量的分布\n",
    "dist = ol.getdistprops(covidtotals.total_cases_pm)\n",
    "pprint.pprint(dist)\n",
    "\n",
    "# 显示离群行\n",
    "sumvars = ['satmath','wageincome20']\n",
    "othervars = ['originalid','highestdegree','gender','maritalstatus']\n",
    "outliers = ol.getoutliers(nls97, sumvars, othervars)\n",
    "outliers.varname.value_counts(sort=False)\n",
    "outliers.loc[outliers.varname=='satmath', othervars + sumvars]\n",
    "outliers.to_csv(\"views/nlsoutliers.csv\")\n",
    "\n",
    "# 绘制序列的直方图或方框图\n",
    "ol.makeplot(nls97.satmath, \"Histogram of SAT Math\", \"SAT Math\")\n",
    "ol.makeplot(nls97.satmath, \"Boxplot of SAT Math\", \"SAT Math\", \"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inright  N      Y\n",
      "inleft           \n",
      "N        0      1\n",
      "Y        2  27472\n",
      "      countryid inleft inright\n",
      "7363         FO      N       Y\n",
      "9716         LQ      Y       N\n",
      "13104        ST      Y       N\n",
      "ltbrazil.csv has 1008 rows.\n",
      "ltcameroon.csv has 48 rows.\n",
      "ltindia.csv has 1116 rows.\n",
      "ltpoland.csv has 120 rows.\n",
      "ltjapan.csv has 1800 rows.\n",
      "ltmexico.csv has 852 rows.\n",
      "ltoman.csv has 288 rows.\n",
      "\n",
      "Different column names for:\n",
      "ltoman.csv\n",
      "Index(['latabs'], dtype='object')\n",
      "\n",
      "Columns Matched: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country\n",
       "Japan       1800\n",
       "India       1116\n",
       "Brazil      1008\n",
       "Mexico       852\n",
       "Oman         288\n",
       "Poland       120\n",
       "Cameroon      48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import combineagg module\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import combineagg as ca\n",
    "import importlib\n",
    "importlib.reload(ca)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 加载数据帧\n",
    "coviddaily = pd.read_csv(\"data/coviddaily.csv\")\n",
    "ltbrazil = pd.read_csv(\"data/ltbrazil.csv\")\n",
    "countries = pd.read_csv(\"data/ltcountries.csv\")\n",
    "locations = pd.read_csv(\"data/ltlocations.csv\")\n",
    "\n",
    "# 按组和时间段汇总面板数据，但不包括在内\n",
    "ca.adjmeans(coviddaily, 'location','new_cases','casedate')\n",
    "ca.adjmeans(coviddaily, 'location','new_cases','casedate', 5000)\n",
    "\n",
    "# 检查数据帧中按值合并的匹配情况\n",
    "ca.checkmerge(countries.copy(), locations.copy(),\\\n",
    "  \"countryid\", \"countryid\")\n",
    "\n",
    "# 将文件夹中的所有pickle文件连接起来，假设它们具有相同的结构\n",
    "landtemps = ca.addfiles(\"data/ltcountry\")\n",
    "landtemps.country.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class_清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "# import the respondent class\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import respondent as rp\n",
    "import importlib\n",
    "importlib.reload(rp)\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# 加载NLS数据，然后创建字典列表\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97list = nls97.to_dict('records')\n",
    "nls97.shape\n",
    "len(nls97list)\n",
    "pprint.pprint(nls97list[0:1])\n",
    "\n",
    "# 遍历列表，每次创建一个响应实例\n",
    "analysislist = []\n",
    "for respdict in nls97list:\n",
    "  resp = rp.Respondent(respdict)\n",
    "  newdict = dict(originalid=respdict['originalid'],\n",
    "    childnum=resp.childnum(),\n",
    "    avgweeksworked=resp.avgweeksworked(),\n",
    "    age=resp.ageby('20201015'),\n",
    "    baenrollment=resp.baenrollment())\n",
    "  analysislist.append(newdict)\n",
    "\n",
    "# 创建pandas数据帧\n",
    "len(analysislist)\n",
    "resp.respondentcnt\n",
    "pprint.pprint(analysislist[0:2])\n",
    "analysis = pd.DataFrame(analysislist)\n",
    "analysis.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json_清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "\n",
    "# import the collection items module\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import collectionitem as ci\n",
    "\n",
    "# 加载美术馆的json数据\n",
    "response = requests.get(\"https://openaccess-api.clevelandart.org/api/artworks/?african_american_artists\")\n",
    "camcollections = json.loads(response.text)\n",
    "camcollections = camcollections['data']\n",
    "\n",
    "# 循环遍历列表，每次创建一个集合项实例\n",
    "analysislist = []\n",
    "for colldict in camcollections:\n",
    "  coll = ci.Collectionitem(colldict)\n",
    "  newdict = dict(id=colldict['id'],\n",
    "    title=colldict['title'],\n",
    "    type=colldict['type'],\n",
    "    creationdate=colldict['creation_date'],\n",
    "    ncreators=coll.ncreators(),\n",
    "    ncitations=coll.ncitations(),\n",
    "    birthyearsall=coll.birthyearsall(),\n",
    "    birthyear=coll.birthyearcreator1())\n",
    "  analysislist.append(newdict)\n",
    "\n",
    "# 创建pandas数据帧\n",
    "len(camcollections)\n",
    "len(analysislist)\n",
    "pprint.pprint(analysislist[0:1])\n",
    "analysis = pd.DataFrame(analysislist)\n",
    "analysis.birthyearsall.value_counts().head()\n",
    "analysis.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "dc = pd.read_csv(\"data/datacheckingtargets.csv\")\n",
    "dc.set_index('varname', inplace=True)\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import runchecks as rc\n",
    "\n",
    "nls97.originalid.head(7)\n",
    "nls97.loc[nls97.originalid==2,\"originalid\"] = 1\n",
    "nls97.loc[nls97.originalid.between(3,7), \"originalid\"] = np.nan\n",
    "nls97.originalid.head(7)\n",
    "nls97[\"highestgradecompleted\"] = nls97.highestgradecompleted.replace(95, np.nan)\n",
    "\n",
    "dc = dc.loc[dc.include==\"Y\"]\n",
    "numvars = dc.loc[dc.type==\"numeric\"].index.to_list()\n",
    "catvars = dc.loc[dc.type==\"categorical\"].index.to_list()\n",
    "idvars = dc.loc[dc.type==\"unique\"].index.to_list()\n",
    "\n",
    "rc.runchecks(nls97,dc,numvars,catvars,idvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流水线_处理_简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# 加载NLS数据\n",
    "landtemps = pd.read_csv(\"data/landtemps2023avgs.csv\")\n",
    "\n",
    "feature_cols = ['latabs','elevation']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(landtemps[feature_cols],\\\n",
    "  landtemps[['avgtemp']], test_size=0.1, random_state=0)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "type(kf)\n",
    "      \n",
    "pipeline = \\\n",
    "  make_pipeline(StandardScaler(),\n",
    "  SimpleImputer(strategy=\"mean\"),LinearRegression(), memory=None)\n",
    "\n",
    "scores = \\\n",
    "  cross_validate(pipeline, X=X_train, y=y_train.values,\n",
    "  cv=kf, scoring=['r2','neg_mean_absolute_error'], \n",
    "  n_jobs=1)\n",
    "\n",
    "print(\"Mean Absolute Error: %.2f, R-squared: %.2f\" % \n",
    "  (scores['test_neg_mean_absolute_error'].mean(),\n",
    "  scores['test_r2'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流水线_预处理_复杂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "from preprocfunc import OutlierTrans\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 加载NLS数据并创建训练和测试DataFrames\n",
    "nls97wages = pd.read_csv(\"data/nls97wages.csv\", low_memory=False)\n",
    "nls97wages.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 设置功能和目标\n",
    "num_cols = ['gpascience','gpaenglish','gpamath',\n",
    "  'gpaoverall','motherhighgrade','fatherhighgrade',\n",
    "  'parentincome','weeksworked20']\n",
    "cat_cols = ['gender']\n",
    "bin_cols = ['completedba']\n",
    "\n",
    "target = nls97wages[['wageincome20']]\n",
    "features = nls97wages[num_cols + cat_cols + bin_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(features,\\\n",
    "  target, test_size=0.2, random_state=0)\n",
    "\n",
    "# 为列转换设置管道\n",
    "standtrans = make_pipeline(OutlierTrans(2),\n",
    "  StandardScaler())\n",
    "cattrans = \\\n",
    "  make_pipeline(SimpleImputer(strategy=\\\n",
    "  \"most_frequent\"),OneHotEncoder(drop_last=True))\n",
    "bintrans = \\\n",
    "  make_pipeline(SimpleImputer(strategy=\\\n",
    "  \"most_frequent\"))\n",
    "\n",
    "coltrans = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"stand\", standtrans, num_cols),\n",
    "    (\"cat\", cattrans, ['gender']),\n",
    "    (\"bin\", bintrans, ['completedba'])\n",
    "  ]\n",
    ")\n",
    "\n",
    "# 在管道中添加特征选择和线性模型，并查看参数估算值\n",
    "lr = LinearRegression()\n",
    "\n",
    "pipe1 = make_pipeline(coltrans,\n",
    "  KNNImputer(n_neighbors=5), lr)\n",
    "\n",
    "ttr=TransformedTargetRegressor(regressor=pipe1,\n",
    "  transformer=StandardScaler())\n",
    "\n",
    "# 运行 kfold 交叉验证\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "scores = cross_validate(ttr, X=X_train, y=y_train,\n",
    "  cv=kf, scoring=('r2', 'neg_mean_absolute_error'),\n",
    "  n_jobs=1)\n",
    "\n",
    "print(\"Mean Absolute Error: %.2f, R-squared: %.2f\" % \n",
    "  (scores['test_neg_mean_absolute_error'].mean(),\n",
    "  scores['test_r2'].mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
