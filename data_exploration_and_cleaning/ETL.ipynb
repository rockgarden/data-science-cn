{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "from invoke import task\n",
    "\n",
    "\n",
    "def load_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file, parse_dates=['start', 'end'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate(df):\n",
    "    bad_time = df.query('start >= end')\n",
    "    if len(bad_time) > 0:\n",
    "        raise ValueError(bad_time)\n",
    "\n",
    "\n",
    "@task\n",
    "def etl(ctx, csv_file):\n",
    "    df = load_csv(csv_file)\n",
    "    validate(df)\n",
    "\n",
    "    db_file = 'rides.db'\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    df.to_sql('rides', conn, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/ships.csv')\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "schema = '''\n",
    "CREATE TABLE ships (\n",
    "    name TEXT,\n",
    "    lat FLOAT NOT NULL,\n",
    "    lng FLOAT NOT NULL\n",
    ");\n",
    "'''\n",
    "\n",
    "db_file = 'cache/ships.db'\n",
    "conn = sqlite3.connect(db_file)\n",
    "conn.executescript(schema)\n",
    "\n",
    "try:\n",
    "    with conn as cur:\n",
    "        cur.execute('BEGIN')\n",
    "        df.to_sql('ships', conn, if_exists='append', index=False)\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "# æŠ¥IntegrityError: NOT NULL constraint failed: ships.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (3.91%) bad rows\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load traffic.csv into \"traffic\" table in sqlite3 database.\n",
    "\n",
    "Drop and report invalid rows.\n",
    "- ip should be valid IP (see ipaddress)\n",
    "- time must not be in the future\n",
    "- path can't be empty\n",
    "- status code must be a valid HTTP status code (see http.HTTPStatus)\n",
    "- size can't be negative or empty\n",
    "\n",
    "Report the percentage of bad rows. Fail the ETL if there are more than 5% bad rows\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "from http import HTTPStatus\n",
    "from ipaddress import ip_address\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "status_codes = set(HTTPStatus)\n",
    "\n",
    "max_bad_percent = 5\n",
    "\n",
    "\n",
    "def is_valid_row(row):\n",
    "    # ip should be valid IP (see ipaddress)\n",
    "    try:\n",
    "        ip_address(row['ip'])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    # time must not be in the future or older than 1 year\n",
    "    now = pd.Timestamp.now()\n",
    "    if row['time'] > now:\n",
    "        return False\n",
    "    \n",
    "    # path can't be empty\n",
    "    if pd.isnull(row['path']) or not row['path'].strip():\n",
    "        return False\n",
    "\n",
    "    # status code must be a valid HTTP status code (see http.HTTPStatus)\n",
    "    if row['status'] not in status_codes:\n",
    "        return False\n",
    "\n",
    "    # size can't be negative or empty\n",
    "    if pd.isnull(row['size']) or row['size'] < 0:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def etl(csv_file, db_file):\n",
    "    df = pd.read_csv(csv_file, parse_dates=['time'])\n",
    "\n",
    "    bad_rows = df[~df.apply(is_valid_row, axis=1)]\n",
    "    if len(bad_rows) > 0:\n",
    "        percent_bad = len(bad_rows)/len(df) * 100\n",
    "        print(f'{len(bad_rows)} ({percent_bad:.2f}%) bad rows')\n",
    "        if percent_bad >= max_bad_percent:\n",
    "            raise ValueError('too many bad rows ({precent_bad:.2f}%)')\n",
    "\n",
    "    df = df[~df.index.isin(bad_rows.index)]\n",
    "    with closing(sqlite3.connect(db_file)) as conn:\n",
    "        conn.execute('BEGIN')\n",
    "        with conn:\n",
    "            df.to_sql('traffic', conn, if_exists='append', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    etl('data/traffic.csv', 'cache/traffic.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
