{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并数据框\n",
    "\n",
    "Combining DataFrames\n",
    "\n",
    "## 垂直组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.width', 58)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 加载喀麦隆和波兰的数据\n",
    "ltcameroon = pd.read_csv(\"data/ltcountry/ltcameroon.csv\")\n",
    "ltoman = pd.read_csv(\"data/ltcountry/ltoman.csv\")\n",
    "\n",
    "# 连接喀麦隆和波兰的数据\n",
    "ltcameroon.shape\n",
    "ltoman.shape\n",
    "ltcameroon.columns\n",
    "ltoman.columns\n",
    "ltcameroon.columns.\\\n",
    "  symmetric_difference(ltoman.columns)\n",
    "ltall = pd.concat([ltcameroon, ltoman])\n",
    "ltall.country.value_counts()\n",
    "ltall[['country','station','temperature',\n",
    "  'latitude','latabs']].\\\n",
    "  sample(5, random_state=3)\n",
    "ltall.groupby(['country'])['latabs'].count()\n",
    "\n",
    "# 创建一个连接文件的函数\n",
    "def concatfiles(filelist):\n",
    "  directory = \"data/ltcountry/\"\n",
    "  ltall = pd.DataFrame()\n",
    "  for filename in filelist:\n",
    "    ltnew = pd.read_csv(directory + filename + \".csv\")\n",
    "    print(filename + \" has \" + \n",
    "      str(ltnew.shape[0]) + \" rows.\")\n",
    "    ltall = pd.concat([ltall, ltnew])\n",
    "  return ltall\n",
    "\n",
    "ltall = concatfiles(['ltcameroon','ltoman'])\n",
    "ltall.country.value_counts()\n",
    "\n",
    "# 连接所有数据文件\n",
    "def concatallfiles():\n",
    "  directory = \"data/ltcountry\"\n",
    "  ltall = pd.DataFrame()\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"): \n",
    "      fileloc = os.path.join(directory, filename)\n",
    "\n",
    "      # 打开下一个文件\n",
    "      with open(fileloc):\n",
    "        ltnew = pd.read_csv(fileloc)\n",
    "        print(filename + \" has \" + \n",
    "          str(ltnew.shape[0]) + \" rows.\")\n",
    "        ltall = pd.concat([ltall, ltnew])\n",
    "\n",
    "        # 检查列中的差异\n",
    "        columndiff = ltall.columns.\\\n",
    "          symmetric_difference(ltnew.columns)\n",
    "        if (not columndiff.empty):\n",
    "          print(\"\", \"Different column names for:\",\n",
    "           filename, columndiff, \"\", sep=\"\\n\")\n",
    "          \n",
    "  return ltall\n",
    "\n",
    "ltall = concatallfiles()\n",
    "\n",
    "ltall[['country','station','month',\n",
    " 'temperature','latitude']].\\\n",
    " sample(5, random_state=1)\n",
    "\n",
    "# 检查连接数据中的值\n",
    "ltall.country.value_counts().sort_index()\n",
    "ltall.groupby(['country']).\\\n",
    "  agg({'temperature':['mean','max','count'],\n",
    "  'latabs':['mean','max','count']})\n",
    "\n",
    "# 修复缺失值\n",
    "ltall['latabs'] = np.where(ltall.country==\"Oman\", ltall.latitude, ltall.latabs)\n",
    "ltall.groupby(['country']).\\\n",
    "  agg({'temperature':['mean','max','count'],\n",
    "  'latabs':['mean','max','count']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一对一合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 52)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97f.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "nls97add = pd.read_csv(\"data/nls97add.csv\")\n",
    "\n",
    "# 查看一些 NLS 数据\n",
    "nls97.head()\n",
    "\n",
    "nls97.shape\n",
    "nls97add.head()\n",
    "nls97add.shape\n",
    "\n",
    "# 检查唯一 ID\n",
    "nls97.originalid.nunique()==nls97.shape[0]\n",
    "nls97add.originalid.nunique()==nls97add.shape[0]\n",
    "\n",
    "# 创建一些不匹配的 ID\n",
    "nls97 = nls97.sort_values('originalid')\n",
    "nls97add = nls97add.sort_values('originalid')\n",
    "nls97.loc[[135335,999406], \"originalid\"] = \\\n",
    "  nls97.originalid+10000\n",
    "nls97.originalid.head(2)\n",
    "nls97add.loc[[0,1], \"originalid\"] = \\\n",
    "  nls97add.originalid+20000\n",
    "nls97add.originalid.head(2)\n",
    "nls97.set_index(\"originalid\", inplace=True)\n",
    "nls97add.set_index(\"originalid\", inplace=True)\n",
    "\n",
    "# 使用连接进行左连接\n",
    "nlsnew = nls97.join(nls97add, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]\n",
    "\n",
    "# 进行左连接和合并\n",
    "nlsnew = pd.merge(nls97, nls97add, on=['originalid'], how=\"left\", validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]\n",
    "\n",
    "# 进行右连接\n",
    "nlsnew = pd.merge(nls97, nls97add, on=['originalid'], how=\"right\", validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]\n",
    "\n",
    "# 进行内连接\n",
    "nlsnew = pd.merge(nls97, nls97add, on=['originalid'], how=\"inner\", validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]\n",
    "\n",
    "# 做外连接\n",
    "nlsnew = pd.merge(nls97, nls97add, on=['originalid'], how=\"outer\", validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]\n",
    "\n",
    "# 创建一个检查 ID 不匹配的函数\n",
    "def checkmerge(dfleft, dfright, idvar):\n",
    "  dfleft['inleft'] = \"Y\"\n",
    "  dfright['inright'] = \"Y\"\n",
    "  dfboth = pd.merge(dfleft[[idvar,'inleft']],\\\n",
    "    dfright[[idvar,'inright']], on=[idvar], how=\"outer\", validate=\"many_to_many\")\n",
    "  dfboth.fillna('N', inplace=True)\n",
    "  print(pd.crosstab(dfboth.inleft, dfboth.inright))\n",
    "\n",
    "checkmerge(nls97.reset_index(),nls97add.reset_index(), \"originalid\")\n",
    "\n",
    "nlsnew = pd.merge(nls97, nls97add, left_on=['originalid'], right_on=['originalid'], how=\"right\", validate=\"many_to_many\")\n",
    "nlsnew.loc[nlsnew.index>9999, ['gender','birthyear','motherage','parentincome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 68)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97weeksworked = pd.read_csv(\"data/nls97weeksworked.csv\")\n",
    "nls97colenr = pd.read_csv(\"data/nls97colenr.csv\")\n",
    "\n",
    "# 查看一些 NLS 数据\n",
    "nls97weeksworked.loc[nls97weeksworked.\\\n",
    "  originalid.isin([2,3])]\n",
    "    \n",
    "nls97weeksworked.shape\n",
    "\n",
    "nls97weeksworked.originalid.nunique()\n",
    "nls97colenr.loc[nls97colenr.\\\n",
    "  originalid.isin([2,3])]\n",
    "\n",
    "nls97colenr.shape\n",
    "nls97colenr.originalid.nunique()\n",
    "\n",
    "# 检查唯一 ID\n",
    "nls97weeksworked.groupby(['originalid','year'])\\\n",
    "  ['originalid'].count().shape\n",
    "nls97colenr.groupby(['originalid','year'])\\\n",
    "  ['originalid'].count().shape\n",
    "\n",
    "# 创建一个检查 ID 不匹配的函数\n",
    "def checkmerge(dfleft, dfright, idvar):\n",
    "  dfleft['inleft'] = \"Y\"\n",
    "  dfright['inright'] = \"Y\"\n",
    "  dfboth = pd.merge(dfleft[idvar + ['inleft']],\\\n",
    "    dfright[idvar + ['inright']], on=idvar, how=\"outer\", validate=\"many_to_many\")\n",
    "  dfboth.fillna('N', inplace=True)\n",
    "  print(pd.crosstab(dfboth.inleft, dfboth.inright))\n",
    "\n",
    "checkmerge(nls97weeksworked.copy(),nls97colenr.copy(), ['originalid','year'])\n",
    "\n",
    "# 使用多个合并列\n",
    "nls97workschool = \\\n",
    "  pd.merge(nls97weeksworked, nls97colenr,\n",
    "  on=['originalid','year'], how=\"inner\", validate=\"many_to_many\")\n",
    "nls97workschool.shape\n",
    "nls97workschool.loc[nls97workschool.\\\n",
    "  originalid.isin([2,3])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一对多合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 53)\n",
    "pd.set_option('display.max_columns', 5)\n",
    "countries = pd.read_csv(\"data/ltcountries.csv\")\n",
    "locations = pd.read_csv(\"data/ltlocations.csv\")\n",
    "\n",
    "# 为地点和国家数据设置索引并打印几行\n",
    "countries.set_index(['countryid'], inplace=True)\n",
    "locations.set_index(['countryid'], inplace=True)\n",
    "countries.head()\n",
    "countries.index.nunique()==countries.shape[0]\n",
    "\n",
    "locations[['locationid','latitude','stnelev']].head(10)\n",
    "\n",
    "# 将国家和地点进行左连接\n",
    "stations = countries.join(locations, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "stations[['locationid','latitude',\n",
    "  'stnelev','country']].head(10)\n",
    "\n",
    "# 重新加载地点文件并检查合并情况\n",
    "countries = pd.read_csv(\"data/ltcountries.csv\")\n",
    "locations = pd.read_csv(\"data/ltlocations.csv\")\n",
    "def checkmerge(dfleft, dfright, idvar):\n",
    "  dfleft['inleft'] = \"Y\"\n",
    "  dfright['inright'] = \"Y\"\n",
    "  dfboth = pd.merge(dfleft[[idvar,'inleft']],\\\n",
    "    dfright[[idvar,'inright']], on=[idvar], how=\"outer\", validate=\"many_to_many\")\n",
    "  dfboth.fillna('N', inplace=True)\n",
    "  print(pd.crosstab(dfboth.inleft, dfboth.inright))\n",
    "  print(dfboth.loc[(dfboth.inleft=='N') | (dfboth.inright=='N')])\n",
    "\n",
    "checkmerge(countries.copy(), locations.copy(), \"countryid\")\n",
    "\n",
    "# 显示一个文件中的行，而不显示另一个文件中的行\n",
    "countries.loc[countries.countryid.isin([\"LQ\",\"ST\"])]\n",
    "locations.loc[locations.countryid==\"FO\"]\n",
    "\n",
    "# 合并地点和国家数据\n",
    "stations = pd.merge(countries, locations, on=[\"countryid\"], how=\"left\", validate=\"many_to_many\")\n",
    "stations[['locationid','latitude',\n",
    "  'stnelev','country']].head(10)\n",
    "stations.shape\n",
    "stations.loc[stations.countryid.isin([\"LQ\",\"ST\"])].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多对多合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 64)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "cmacitations = pd.read_csv(\"data/cmacitations.csv\")\n",
    "cmacreators = pd.read_csv(\"data/cmacreators.csv\")\n",
    "\n",
    "# 看看引文数据\n",
    "cmacitations['citation'] = cmacitations.citation.str[0:15]\n",
    "cmacitations.head(10)\n",
    "cmacitations.shape\n",
    "cmacitations.itemid.nunique()\n",
    "\n",
    "# 查看创作者数据\n",
    "cmacreators['creator'] = cmacreators.creator.str[0:15]\n",
    "cmacreators.loc[:,['itemid','creator','birth_year',\n",
    " 'creatorid']].head(10)\n",
    "cmacreators.shape\n",
    "cmacreators.itemid.nunique()\n",
    "cmacreators.creatorid.nunique()\n",
    "\n",
    "# 显示重复的引文合并值\n",
    "cmacitations.itemid.value_counts().head(10)\n",
    "\n",
    "# s显示创作者的重复合并值\n",
    "cmacreators.itemid.value_counts().head(10)\n",
    "\n",
    "# 检查合并\n",
    "def checkmerge(dfleft, dfright, idvar):\n",
    "  dfleft['inleft'] = \"Y\"\n",
    "  dfright['inright'] = \"Y\"\n",
    "  dfboth = pd.merge(dfleft[[idvar,'inleft']],\\\n",
    "    dfright[[idvar,'inright']], on=[idvar], how=\"outer\", validate=\"many_to_many\")\n",
    "  dfboth.fillna('N', inplace=True)\n",
    "  print(pd.crosstab(dfboth.inleft, dfboth.inright))\n",
    "\n",
    "checkmerge(cmacitations.copy(), cmacreators.copy(), \"itemid\")\n",
    "\n",
    "# 显示两个数据帧中重复的合并列\n",
    "cmacitations.loc[cmacitations.itemid==124733]\n",
    "cmacreators.loc[cmacreators.itemid==124733,\n",
    "  ['itemid','creator','birth_year','title']]\n",
    "\n",
    "# 进行多对多合并\n",
    "cma = pd.merge(cmacitations, cmacreators, on=['itemid'], how=\"outer\", validate=\"many_to_many\")\n",
    "cma.set_index(\"itemid\", inplace=True)\n",
    "cma.loc[124733, ['citation','creator','birth_year']]\n",
    "\n",
    "cma.info()\n",
    "\n",
    "cma.loc[75551]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inright  N      Y\n",
      "inleft           \n",
      "N        0      1\n",
      "Y        2  27472\n",
      "      countryid inleft inright\n",
      "7363         FO      N       Y\n",
      "9716         LQ      Y       N\n",
      "13104        ST      Y       N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27474, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countries = pd.read_csv(\"data/ltcountries.csv\")\n",
    "locations = pd.read_csv(\"data/ltlocations.csv\")\n",
    "\n",
    "# 检查合并列是否匹配\n",
    "def checkmerge(dfleft, dfright, mergebyleft, mergebyright):\n",
    "  dfleft['inleft'] = \"Y\"\n",
    "  dfright['inright'] = \"Y\"\n",
    "  dfboth = \\\n",
    "    pd.merge(dfleft[[mergebyleft,'inleft']],\\\n",
    "    dfright[[mergebyright,'inright']],\\\n",
    "    left_on=[mergebyleft],\\\n",
    "    right_on=[mergebyright], how=\"outer\", validate=\"many_to_many\")\n",
    "  dfboth.fillna('N', inplace=True)\n",
    "  print(pd.crosstab(dfboth.inleft,\n",
    "    dfboth.inright))\n",
    "  print(dfboth.loc[(dfboth.inleft=='N') | \\\n",
    "    (dfboth.inright=='N')].head(20))\n",
    "\n",
    "checkmerge(countries.copy(), locations.copy(), \"countryid\", \"countryid\")\n",
    "\n",
    "# 合并地点和国家数据\n",
    "stations = pd.merge(countries, locations, left_on=[\"countryid\"], right_on=[\"countryid\"],\\\n",
    "    how=\"left\", validate=\"many_to_many\")\n",
    "stations[['locationid','latitude',\n",
    "  'stnelev','country']].head(10)\n",
    "stations.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
