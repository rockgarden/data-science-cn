{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "import sklearn.metrics as skmet\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树分类\n",
    "\n",
    "decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "from preprocfunc import MakeOrdinal,\\\n",
    "  ReplaceVals\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# load the health information data\n",
    "healthinfo = pd.read_csv(\"data/healthinfosample.csv\")\n",
    "healthinfo.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# take a look at some of the data\n",
    "healthinfo.heartdisease.value_counts()\n",
    "\n",
    "healthinfo['heartdisease'] = \\\n",
    "  np.where(healthinfo.heartdisease=='No',0,1).\\\n",
    "  astype('int')\n",
    "\n",
    "healthinfo.heartdisease.value_counts()\n",
    "\n",
    "healthinfo.agecategory.value_counts().\\\n",
    "  sort_index().reset_index()\n",
    "\n",
    "# identify numeric and categorical data\n",
    "num_cols = ['bmi','physicalhealthbaddays',\n",
    "   'mentalhealthbaddays','sleeptimenightly']\n",
    "binary_cols = ['smoking','alcoholdrinkingheavy',\n",
    "  'stroke','walkingdifficult','physicalactivity',\n",
    "  'asthma','kidneydisease','skincancer']\n",
    "cat_cols = ['gender','ethnicity']\n",
    "spec_cols1 = ['agecategory']\n",
    "spec_cols2 = ['genhealth','diabetic']\n",
    "\n",
    "rep_dict = {\n",
    "  'genhealth': {'Poor':0,'Fair':1,'Good':2,\n",
    "    'Very good':3,'Excellent':4},\n",
    "  'diabetic': {'No':0,\n",
    "    'No, borderline diabetes':0,'Yes':1,\n",
    "    'Yes (during pregnancy)':1}           \n",
    "}\n",
    "\n",
    "\n",
    "# create training and testing DataFrames\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "  train_test_split(healthinfo[num_cols + \n",
    "    binary_cols + cat_cols + spec_cols1 +\n",
    "    spec_cols2],\\\n",
    "  healthinfo[['heartdisease']], test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "\n",
    "# setup column transformations\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "spectrans1 = make_pipeline(MakeOrdinal())\n",
    "spectrans2 = make_pipeline(ReplaceVals(rep_dict))\n",
    "bintrans = make_pipeline(ohe)\n",
    "cattrans = make_pipeline(ohe)\n",
    "coltrans = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"bin\", bintrans, binary_cols),\n",
    "    (\"cat\", cattrans, cat_cols),\n",
    "    (\"spec1\", spectrans1, spec_cols1),\n",
    "    (\"spec2\", spectrans2, spec_cols2),\n",
    "  ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "coltrans.fit(X_train.sample(1000))\n",
    "\n",
    "new_binary_cols = \\\n",
    "  coltrans.\\\n",
    "  named_transformers_['bin'].\\\n",
    "  named_steps['onehotencoder'].\\\n",
    "  get_feature_names_out(binary_cols)\n",
    "new_cat_cols = \\\n",
    "  coltrans.\\\n",
    "  named_transformers_['cat'].\\\n",
    "  named_steps['onehotencoder'].\\\n",
    "  get_feature_names_out(cat_cols)\n",
    "\n",
    "new_cols = np.concatenate((new_binary_cols, \n",
    "  new_cat_cols, np.array(spec_cols1 + spec_cols2 +\n",
    "  num_cols)))\n",
    "\n",
    "np.set_printoptions(linewidth=55)\n",
    "new_cols\n",
    "\n",
    "# construct a pipeline with preprocessing, feature selection, and logistic model\n",
    "catcolscnt = new_binary_cols.shape[0] + \\\n",
    "  new_cat_cols.shape[0]\n",
    "\n",
    "SMOTENC(categorical_features=np.arange(0,catcolscnt),\n",
    "  random_state=0)\n",
    "smotenc = \\\n",
    "  SMOTENC(categorical_features=np.arange(0,catcolscnt),\n",
    "  random_state=0)\n",
    "\n",
    "dtc_example = DecisionTreeClassifier(min_samples_leaf=30,\n",
    "  max_depth=2)\n",
    "\n",
    "pipe0 = make_pipeline(coltrans, smotenc, dtc_example)\n",
    "\n",
    "pipe0.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pipe0.named_steps['smotenc']\n",
    "\n",
    "# get feature importances\n",
    "feature_imp = \\\n",
    "  pipe0.named_steps['decisiontreeclassifier'].\\\n",
    "  tree_.compute_feature_importances(normalize=False)\n",
    "feature_impgt0 = feature_imp>0\n",
    "feature_implabs = np.column_stack((feature_imp.\\\n",
    "  ravel(), new_cols))\n",
    "feature_implabs[feature_impgt0]\n",
    "\n",
    "plot_tree(pipe0.named_steps['decisiontreeclassifier'],\n",
    "  feature_names=new_cols, \n",
    "  class_names=['No Disease','Disease'], fontsize=10)\n",
    "\n",
    "\n",
    "pred = pipe0.predict(X_test)\n",
    "\n",
    "print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n",
    "  (skmet.accuracy_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred,\n",
    "    pos_label=0),\n",
    "  skmet.precision_score(y_test.values.ravel(), pred)))\n",
    "\n",
    "# do some hyperparameter tuning\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "pipe1 = make_pipeline(coltrans, smotenc, dtc)\n",
    "\n",
    "dtc_params = {\n",
    " 'decisiontreeclassifier__min_samples_leaf': randint(100, 1200),\n",
    " 'decisiontreeclassifier__max_depth': randint(2, 11)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(pipe1, dtc_params, cv=5,\n",
    "  n_iter=20, scoring=\"roc_auc\")\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "\n",
    "results = \\\n",
    "  pd.DataFrame(rs.cv_results_['mean_test_score'], \\\n",
    "    columns=['meanscore']).\\\n",
    "  join(pd.DataFrame(rs.cv_results_['params']), \\\n",
    "      how=\"left\", on=None, validate=\"many_to_many\").\\\n",
    "  sort_values(['meanscore'], ascending=False).\\\n",
    "  rename(columns=\\\n",
    "    {'decisiontreeclassifier__max_depth':'maxdepth',\n",
    "     'decisiontreeclassifier__min_samples_leaf':\\\n",
    "     'samples'})\n",
    "\n",
    "results\n",
    "\n",
    "pred2 = rs.predict(X_test)\n",
    "\n",
    "cm = skmet.confusion_matrix(y_test, pred2)\n",
    "cmplot = \\\n",
    "  skmet.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "  display_labels=['Negative', 'Positive'])\n",
    "cmplot.plot()\n",
    "cmplot.ax_.\\\n",
    "  set(title='Heart Disease Prediction Confusion Matrix', \n",
    "  xlabel='Predicted Value', ylabel='Actual Value')\n",
    "\n",
    "\n",
    "print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n",
    "  (skmet.accuracy_score(y_test.values.ravel(), pred2),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred2),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred2,\n",
    "    pos_label=0),\n",
    "  skmet.precision_score(y_test.values.ravel(), pred2)))\n",
    "\n",
    "# this can be used to save the transformed data; it is not in the chapter text\n",
    "healthinfosample_enc = pd.DataFrame(coltrans.fit_transform(healthinfo[num_cols + \n",
    "  binary_cols + cat_cols + spec_cols1 + spec_cols2]), columns=new_cols, index=healthinfo.index).\\\n",
    "      join(healthinfo[['heartdisease']], how=\"left\", on=None, validate=\"many_to_many\")\n",
    "\n",
    "healthinfosample_enc.to_csv('data/healthinfosample_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林分类\n",
    "\n",
    "random forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import healthinfo as hi\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "\n",
    "X_train = hi.X_train\n",
    "X_test = hi.X_test\n",
    "y_train = hi.y_train\n",
    "y_test = hi.y_test\n",
    "\n",
    "# do some hyperparameter tuning\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "pipe1 = make_pipeline(hi.coltrans, hi.smotenc, rfc)\n",
    "\n",
    "rfc_params = {\n",
    " 'randomforestclassifier__min_samples_leaf':\n",
    "    randint(100, 1200),\n",
    " 'randomforestclassifier__max_depth': \n",
    "    randint(2, 20),\n",
    " 'randomforestclassifier__n_estimators': \n",
    "    randint(100, 3000),\n",
    " 'randomforestclassifier__criterion': \n",
    "    ['gini','entropy']\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(pipe1, rfc_params, cv=5, \n",
    "  n_iter=20, scoring=\"roc_auc\")\n",
    "\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "rs.named_transformer['estimator']\n",
    "rs.named_steps['randomforestclassifier']\n",
    "rs.best_estimator_['randomforestclassifier'].feature_importances_\n",
    "\n",
    "\n",
    "feature_imp = pd.Series(rs.\\\n",
    "  best_estimator_['randomforestclassifier'].\\\n",
    "  feature_importances_, index=hi.new_cols)\n",
    "feature_imp.loc[feature_imp>0.01].\\\n",
    "    plot(kind='barh')\n",
    "plt.tight_layout()    \n",
    "\n",
    "\n",
    "pred = rs.predict(X_test)\n",
    "\n",
    "print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n",
    "  (skmet.accuracy_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred,\n",
    "    pos_label=0),\n",
    "  skmet.precision_score(y_test.values.ravel(), pred)))\n",
    "\n",
    "\n",
    "cm = skmet.confusion_matrix(y_test, pred)\n",
    "cmplot = skmet.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "cmplot.plot()\n",
    "cmplot.ax_.set(title='Heart Disease Prediction Confusion Matrix', \n",
    "  xlabel='Predicted Value', ylabel='Actual Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度提升决策树\n",
    "\n",
    "gradient boosted decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uniform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     18\u001b[0m gbc \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m pipe1 \u001b[38;5;241m=\u001b[39m make_pipeline(hi\u001b[38;5;241m.\u001b[39mcoltrans, hi\u001b[38;5;241m.\u001b[39msmotenc, gbc)\n\u001b[1;32m     22\u001b[0m gbc_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradientboostingclassifier__min_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     24\u001b[0m      randint(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1200\u001b[39m),\n\u001b[1;32m     25\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradientboostingclassifier__min_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     26\u001b[0m      randint(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1200\u001b[39m),\n\u001b[1;32m     27\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradientboostingclassifier__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     28\u001b[0m      randint(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m     29\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradientboostingclassifier__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m      \u001b[43muniform\u001b[49m(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m),\n\u001b[1;32m     31\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradientboostingclassifier__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     32\u001b[0m      randint(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1200\u001b[39m)\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     35\u001b[0m rs \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(pipe1, gbc_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     36\u001b[0m   n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     37\u001b[0m   n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m rs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uniform' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/helperfunctions\")\n",
    "import healthinfo as hi\n",
    "\n",
    "pd.set_option('display.width', 78)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "X_train = hi.X_train\n",
    "X_test = hi.X_test\n",
    "y_train = hi.y_train\n",
    "y_test = hi.y_test\n",
    "\n",
    "# do some hyperparameter tuning\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "pipe1 = make_pipeline(hi.coltrans, hi.smotenc, gbc)\n",
    "\n",
    "gbc_params = {\n",
    " 'gradientboostingclassifier__min_samples_leaf':\n",
    "     randint(100, 1200),\n",
    " 'gradientboostingclassifier__min_samples_split':\n",
    "     randint(100, 1200),\n",
    " 'gradientboostingclassifier__max_depth':\n",
    "     randint(2, 20),\n",
    " 'gradientboostingclassifier__learning_rate':\n",
    "     uniform(loc=0.02, scale=0.25),\n",
    " 'gradientboostingclassifier__n_estimators':\n",
    "     randint(100, 1200)\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(pipe1, gbc_params, cv=5, \n",
    "  n_iter=25, scoring=\"roc_auc\", random_state=42,\n",
    "  n_jobs=-1)\n",
    "rs.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rs.best_params_\n",
    "rs.best_score_\n",
    "\n",
    "feature_imp = pd.Series(rs.\\\n",
    "  best_estimator_['gradientboostingclassifier'].\\\n",
    "  feature_importances_, index=hi.new_cols)\n",
    "feature_imp.loc[feature_imp>0.01].\\\n",
    "    plot(kind='barh')\n",
    "plt.tight_layout()    \n",
    "\n",
    "pred = rs.predict(X_test)\n",
    "\n",
    "print(\"accuracy: %.2f, sensitivity: %.2f, specificity: %.2f, precision: %.2f\"  %\n",
    "  (skmet.accuracy_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred),\n",
    "  skmet.recall_score(y_test.values.ravel(), pred,\n",
    "    pos_label=0),\n",
    "  skmet.precision_score(y_test.values.ravel(), pred)))\n",
    "\n",
    "cm = skmet.confusion_matrix(y_test, pred)\n",
    "cmplot = skmet.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "cmplot.plot()\n",
    "cmplot.ax_.set(title='Heart Disease Prediction Confusion Matrix', \n",
    "  xlabel='Predicted Value', ylabel='Actual Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
