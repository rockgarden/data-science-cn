{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying and Fixing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 识别缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "读取数据\n",
    "\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "查看缺失值情况\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "删除包含缺失值的行\n",
    "\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "用平均值填充缺失值\n",
    "\n",
    "\n",
    "df_filled = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.width', 70)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 在读取read_csv（）之类的文件的函数中，空字符串（空白）和字符串’NaN’，'null’默认情况下视为缺失值。\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "covidtotals = pd.read_csv(\"data/covidtotalswithmissings.csv\", low_memory=False)\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "# 检查任意列上是否有空值\n",
    "print(covidtotals.isnull().sum())\n",
    "covidtotals.isnull().any(axis=1)\n",
    "\n",
    "# 检查人口统计栏是否缺失\n",
    "covidtotals.shape\n",
    "demovars = ['pop_density','aged_65_older',\n",
    "   'gdp_per_capita','life_expectancy','hum_dev_ind']\n",
    "covidtotals[demovars].isnull().sum(axis=0)\n",
    "demovarsmisscnt = covidtotals[demovars].isnull().sum(axis=1)\n",
    "demovarsmisscnt.value_counts().sort_index()\n",
    "covidtotals.loc[demovarsmisscnt>=4, ['location'] + demovars].\\\n",
    "  sample(5, random_state=1).T\n",
    "\n",
    "# 检查累积栏是否有缺失\n",
    "totvars = ['location','total_cases_pm','total_deaths_pm']\n",
    "covidtotals[totvars].isnull().sum(axis=0)\n",
    "totvarsmisscnt = covidtotals[totvars].isnull().sum(axis=1)\n",
    "totvarsmisscnt.value_counts().sort_index()\n",
    "\n",
    "# 将逻辑缺失设置为实际缺失\n",
    "nlsparents = nls97.iloc[:,-4:]\n",
    "nlsparents.loc[nlsparents.motherhighgrade.between(-5,-1),\n",
    "   'motherhighgrade'].value_counts()\n",
    "nlsparents.loc[nlsparents.transform(lambda x: x.between(-5,-1)).\\\n",
    "  any(axis=1)]\n",
    "\n",
    "nlsparents.transform(lambda x: x.between(-5,-1)).sum()\n",
    "\n",
    "nlsparents.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "\n",
    "print(nlsparents.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 清洗缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 根据 NLS 数据建立学籍和人口数据框架\n",
    "schoolrecordlist = ['satverbal','satmath','gpaoverall',\n",
    "  'gpaenglish',  'gpamath','gpascience','highestdegree',\n",
    "  'highestgradecompleted']\n",
    "\n",
    "schoolrecord = nls97[schoolrecordlist]\n",
    "schoolrecord.shape\n",
    "\n",
    "# 检查学籍数据是否有遗漏\n",
    "schoolrecord.isnull().sum(axis=0)\n",
    "misscnt = schoolrecord.isnull().sum(axis=1)\n",
    "misscnt.value_counts().sort_index()\n",
    "schoolrecord.loc[misscnt>=7].head(4).T\n",
    "\n",
    "# 删除几乎所有缺失数据的行\n",
    "schoolrecord = schoolrecord.dropna(thresh=2)\n",
    "schoolrecord.shape\n",
    "schoolrecord.isnull().sum(axis=1).value_counts().sort_index()\n",
    "\n",
    "# 为缺失值赋值\n",
    "schoolrecord = nls97[schoolrecordlist]\n",
    "print(schoolrecord.gpaoverall.isnull().sum())\n",
    "schoolrecord.gpaoverall.agg(['mean','std','count'])\n",
    "print(schoolrecord.gpaoverall.agg(['mean','std','count']))\n",
    "schoolrecord.fillna({\"gpaoverall\":\\\n",
    " schoolrecord.gpaoverall.mean()}, \n",
    " inplace=True)\n",
    "print(schoolrecord.gpaoverall.isnull().sum())\n",
    "print(schoolrecord.gpaoverall.agg(['mean','std','count']))\n",
    "\n",
    "schoolrecord.fillna({\"gpaoverall\":\\\n",
    " schoolrecord.gpaoverall.mean()}, \n",
    " inplace=True)\n",
    "\n",
    "# 使用正向填充\n",
    "wageincome20 = nls97.wageincome20.copy(deep=True)\n",
    "print(wageincome20.isnull().sum())\n",
    "wageincome20.head().T\n",
    "wageincome20.ffill(inplace=True)\n",
    "wageincome20.head().T\n",
    "print(wageincome20.isnull().sum())\n",
    "\n",
    "# 使用反向填充\n",
    "wageincome20 = nls97.wageincome20.copy(deep=True)\n",
    "wageincome20.head().T\n",
    "print(wageincome20.std())\n",
    "wageincome20.bfill(inplace=True)\n",
    "wageincome20.head().T\n",
    "print(wageincome20.std())\n",
    "\n",
    "# 用各组平均值填补缺漏\n",
    "\n",
    "# print(nls97.weeksworked20.mean())\n",
    "\n",
    "# print(nls97.groupby(['highestdegree'])['weeksworked20'].mean())\n",
    "\n",
    "nls97.loc[nls97.highestdegree.notnull(), 'weeksworked20imp'] = \\\n",
    "  nls97.loc[nls97.highestdegree.notnull()].\\\n",
    "  groupby(['highestdegree'])['weeksworked20'].\\\n",
    "  transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "print(nls97[['highestdegree','weeksworked20imp','weeksworked20','highestdegree']].\\\n",
    "  head(10))\n",
    "print(nls97[['weeksworked20imp','weeksworked20']].\\\n",
    "  agg(['mean','std', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97b.csv\")\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# set up school record and demographic data frames from the NLS data\n",
    "schoolrecordlist = ['satverbal','satmath','gpaoverall','gpaenglish',\n",
    "  'gpamath','gpascience','highestdegree','highestgradecompleted']\n",
    "\n",
    "schoolrecord = nls97[schoolrecordlist]\n",
    "schoolrecord.shape\n",
    "\n",
    "# check the school record data for missings\n",
    "schoolrecord.isnull().sum(axis=0)\n",
    "misscnt = schoolrecord.isnull().sum(axis=1)\n",
    "misscnt.value_counts().sort_index()\n",
    "schoolrecord.loc[misscnt>=7].head(4).T\n",
    "\n",
    "# remove rows with almost all missing data\n",
    "schoolrecord = schoolrecord.dropna(thresh=2)\n",
    "schoolrecord.shape\n",
    "schoolrecord.isnull().sum(axis=1).value_counts().sort_index()\n",
    "\n",
    "# assign mean values to missings\n",
    "schoolrecord.gpaoverall.agg(['mean','std','count'])\n",
    "schoolrecord.gpaoverall.\\\n",
    "  fillna(schoolrecord.gpaoverall.\\\n",
    "  mean(), inplace=True)\n",
    "schoolrecord.gpaoverall.isnull().sum()\n",
    "schoolrecord.gpaoverall.agg(['mean','std','count'])\n",
    "\n",
    "# use forward fill\n",
    "wageincome = nls97.wageincome.copy(deep=True)\n",
    "wageincome.isnull().sum()\n",
    "wageincome.agg(['mean','std','count'])\n",
    "wageincome.head().T\n",
    "\n",
    "wageincome.fillna(method='ffill', inplace=True)\n",
    "wageincome.head().T\n",
    "wageincome.isnull().sum()\n",
    "wageincome.agg(['mean','std','count'])\n",
    "\n",
    "wageincome = nls97.wageincome.copy(deep=True)\n",
    "wageincome.fillna(method='bfill', inplace=True)\n",
    "wageincome.head().T\n",
    "wageincome.agg(['mean','std','count'])\n",
    "\n",
    "# fill missings with the average by group\n",
    "nls97.weeksworked17.mean()\n",
    "nls97.groupby(['highestdegree'])['weeksworked17'].mean()\n",
    "# nls97.loc[~nls97.highestdegree.isnull(), 'weeksworked17imp'] = \\\n",
    "#   nls97.loc[~nls97.highestdegree.isnull()].\\\n",
    "#   groupby(['highestdegree'])['weeksworked17'].\\\n",
    "#   apply(lambda group: group.fillna(np.mean(group)))\n",
    "\n",
    "# nls97[['weeksworked17imp','weeksworked17','highestdegree']].\\\n",
    "#   head(10)\n",
    "# nls97[['weeksworked17imp','weeksworked17']].\\\n",
    "#   agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分组填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- encoding=utf8 -*-\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "# 分组填充：按指定列对目标数据分组，取分组中要填充属性值的平均值或中值来替换或生成中的属性值；\n",
    "\n",
    "# 导入相应数据库客户端\n",
    "import mysql.connector as mdb\n",
    "\n",
    "# 引入并配置 pandas 显示参数\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# 设置目标 table 查询语句以提取数据\n",
    "targettable = \"name\"\n",
    "\n",
    "# 使用 mysql api 和 read_sql() 从 mysql 获取和加载数据\n",
    "host = \"pdccmysql\"\n",
    "user = \"pdccuser\"\n",
    "password = \"pdccpass\"\n",
    "database = \"pdccschema\"\n",
    "connmysql = mdb.connect(host=host,database=database,user=user,password=password)\n",
    "df = pd.read_sql_table(table_name=targettable,con=connmysql)    # 生成 DataFrame\n",
    "connmysql.close()\n",
    "\n",
    "# 将 DataFrame 中的一个或多个列设置为索引\n",
    "df.set_index([\"column1_name\",'column2_name'], inplace=True)\n",
    "\n",
    "# 基于 column２ 分组计算目标 column３ 的 mean/median 值并对该列的空值进行填充 \n",
    "df.loc[df.column２.notnull(), 'column３'] = \\\n",
    "  df.loc[df.column２.notnull()].\\\n",
    "  groupby(['column２'])['column３'].\\\n",
    "  transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 写入数据库，method = 'multi' 需要数据库支持 \n",
    "df.to_sql(name=targettable,con=connmysql,if_exists='replace',chunksize=1000)\n",
    "connmysql.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分箱填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- encoding=utf8 -*-\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "# 分箱填充：根据等级或样本量化值将变量离散成大小相等的桶，取箱中属性值的平均值或中值来替换或生成“箱”中的属性值；\n",
    "\n",
    "# 导入相应数据库客户端\n",
    "import mysql.connector as mdb\n",
    "\n",
    "# 引入并配置 pandas 显示参数\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# 设置目标 table 查询语句以提取数据\n",
    "targettable = \"name\"\n",
    "\n",
    "# 使用 mysql api 和 read_sql() 从 mysql 获取和加载数据\n",
    "host = \"pdccmysql\"\n",
    "user = \"pdccuser\"\n",
    "password = \"pdccpass\"\n",
    "database = \"pdccschema\"\n",
    "connmysql = mdb.connect(host=host,database=database,user=user,password=password)\n",
    "df = pd.read_sql_table(table_name=targettable,con=connmysql)    # 生成 DataFrame\n",
    "connmysql.close()\n",
    "\n",
    "# 将 DataFrame 中的一个或多个列设置为索引\n",
    "df.set_index([\"column1_name\",'column2_name'], inplace=True)\n",
    "\n",
    "# 指定 column 进行分箱操作，并新增分箱数据列 column_qcut，分箱数据 q 需按数据实际情况取\n",
    "df['column3_qcut'] = pd.\\\n",
    "  qcut(df['column3'],\n",
    "       q=100, precision=0, duplicates='drop')\n",
    "\n",
    "# 通过 column_qcut 分组计算目标 column 的 mean/median 值并对该列的空值进行填充 \n",
    "df.loc[df.column3_qcut.notnull(), 'column4'] = \\\n",
    "  df.loc[df.column3_qcut.notnull()].\\\n",
    "  groupby(['column3_qcut'])['column4'].\\\n",
    "  transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 写入数据库，method = 'multi' 需要数据库支持 \n",
    "df.to_sql(name=targettable,con=connmysql,if_exists='replace',chunksize=1000)\n",
    "connmysql.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.width', 74)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 检查与工资收入的相关性\n",
    "\n",
    "nls97[['wageincome20','highestdegree','weeksworked20','parentincome']].info()\n",
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97.groupby(['highestdegree','hdegnum']).size()\n",
    "nls97.parentincome.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "nls97[['wageincome20','hdegnum','weeksworked20','parentincome']].corr()\n",
    "\n",
    "# 检查缺少工资收入数据的人是否有所不同\n",
    "# nls97.wageincome20.describe()\n",
    "# nls97.loc[nls97.weeksworked20==0,'wageincome20'] = 0\n",
    "nls97weeksworked = nls97.loc[nls97.weeksworked20>0]\n",
    "nls97weeksworked.shape\n",
    "nls97weeksworked['missingwageincome'] = \\\n",
    "  np.where(nls97weeksworked.wageincome20.isnull(),1,0)\n",
    "nls97weeksworked.groupby(['missingwageincome'])[['hdegnum',\n",
    "  'parentincome','weeksworked20']].\\\n",
    "  agg(['mean','count'])\n",
    "\n",
    "# 准备回归数据 \n",
    "# nls97.weeksworked20.fillna(nls97.weeksworked20.mean(), inplace=True)\n",
    "nls97weeksworked.parentincome. \\\n",
    "  fillna(nls97weeksworked.parentincome.mean(), inplace=True)\n",
    "nls97weeksworked['degltcol'] = \\\n",
    "  np.where(nls97weeksworked.hdegnum<=2,1,0)\n",
    "nls97weeksworked['degcol'] = \\\n",
    "  np.where(nls97weeksworked.hdegnum.between(3,4),1,0)\n",
    "nls97weeksworked['degadv'] = \\\n",
    "  np.where(nls97weeksworked.hdegnum>4,1,0)\n",
    "\n",
    "# 拟合线性回归模型：返回每个观测值的影响，同时返回模型系数\n",
    "def getlm(df, ycolname, xcolnames):\n",
    "  df = df[[ycolname] + xcolnames].dropna()\n",
    "  y = df[ycolname]\n",
    "  X = df[xcolnames]\n",
    "  X = sm.add_constant(X)\n",
    "  lm = sm.OLS(y, X).fit()\n",
    "  coefficients = pd.DataFrame(zip(['constant'] + xcolnames,\n",
    "    lm.params, lm.pvalues), columns=['features','params',\n",
    "    'pvalues'])\n",
    "  return coefficients, lm\n",
    "\n",
    "# nls97 = nls97.loc[nls97.weeksworked20>0]\n",
    "xvars = ['weeksworked20','parentincome','degcol','degadv']\n",
    "coefficients, lm = getlm(nls97weeksworked, 'wageincome20', xvars)\n",
    "coefficients\n",
    "\n",
    "nls97weeksworked.dtypes\n",
    "\n",
    "# 生成预测\n",
    "pred = lm.predict(sm.add_constant(nls97weeksworked[xvars])).\\\n",
    "  to_frame().rename(columns= {0: 'pred'})\n",
    "nls97weeksworked = nls97weeksworked.join(pred)\n",
    "\n",
    "nls97weeksworked['wageincomeimp'] = \\\n",
    "  np.where(nls97weeksworked.wageincome20.isnull(),\\\n",
    "  nls97weeksworked.pred, nls97weeksworked.wageincome20)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97weeksworked[['wageincomeimp','wageincome20'] + xvars].\\\n",
    "  sample(10, random_state=7)\n",
    "nls97weeksworked[['wageincomeimp','wageincome20']].\\\n",
    "  agg(['count','mean','std'])\n",
    "\n",
    "# 增加一个误差项\n",
    "np.random.seed(0)\n",
    "randomadd = np.random.normal(0, lm.resid.std(), \n",
    "   nls97weeksworked.shape[0])\n",
    "randomadddf = pd.DataFrame(randomadd, columns=['randomadd'],\n",
    "   index=nls97weeksworked.index)\n",
    "nls97weeksworked = nls97weeksworked.join(randomadddf)\n",
    "nls97weeksworked['stochasticpred'] = \\\n",
    "   nls97weeksworked.pred + nls97weeksworked.randomadd\n",
    "\n",
    "nls97weeksworked['wageincomeimpstoc'] = \\\n",
    "  np.where(nls97weeksworked.wageincome20.isnull(),\n",
    "  nls97weeksworked.stochasticpred, nls97weeksworked.wageincome20)\n",
    "\n",
    "nls97weeksworked[['wageincomeimpstoc','wageincome20']].\\\n",
    "  agg(['count','mean','std'])\n",
    "\n",
    "# nls97weeksworked = nls97weeksworked.drop(columns=['randomadd','stochasticpred','wageincomeimpstoc'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97b.csv\")\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# check correlations with wageincome\n",
    "\n",
    "nls97[['wageincome','highestdegree','weeksworked16','parentincome']].info()\n",
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97.groupby(['highestdegree','hdegnum']).size()\n",
    "nls97.parentincome.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "nls97[['wageincome','hdegnum','weeksworked16','parentincome']].corr()\n",
    "\n",
    "# check to see if folks with missing wage income data are different\n",
    "nls97['missingwageincome'] = np.where(nls97.wageincome.isnull(),1,0)\n",
    "nls97.groupby(['missingwageincome'])[['hdegnum','parentincome',\\\n",
    "  'weeksworked16']].agg(['mean','count'])\n",
    "\n",
    "# prepare data to run regression\n",
    "nls97.weeksworked16.fillna(nls97.weeksworked16.mean(), inplace=True)\n",
    "nls97.parentincome.fillna(nls97.parentincome.mean(), inplace=True)\n",
    "nls97['degltcol'] = np.where(nls97.hdegnum<=2,1,0)\n",
    "nls97['degcol'] = np.where(nls97.hdegnum.between(3,4),1,0)\n",
    "nls97['degadv'] = np.where(nls97.hdegnum>4,1,0)\n",
    "\n",
    "# fit a linear regression model\n",
    "# return the influence of each observation\n",
    "# also return model coefficients\n",
    "def getlm(df, ycolname, xcolnames):\n",
    "  df = df[[ycolname] + xcolnames].dropna()\n",
    "  y = df[ycolname]\n",
    "  X = df[xcolnames]\n",
    "  X = sm.add_constant(X)\n",
    "  lm = sm.OLS(y, X).fit()\n",
    "  coefficients = pd.DataFrame(zip(['constant'] + xcolnames,\n",
    "    lm.params, lm.pvalues), columns=['features','params',\n",
    "    'pvalues'])\n",
    "  return coefficients, lm\n",
    "\n",
    "xvars = ['weeksworked16','parentincome','degcol','degadv']\n",
    "coefficients, lm = getlm(nls97, 'wageincome', xvars)\n",
    "coefficients\n",
    "\n",
    "# generate predictions\n",
    "pred = lm.predict(sm.add_constant(nls97[xvars])).\\\n",
    "  to_frame().rename(columns= {0: 'pred'})\n",
    "nls97 = nls97.join(pred, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "nls97['wageincomeimp'] = np.where(nls97.wageincome.isnull(),\\\n",
    "  nls97.pred, nls97.wageincome)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97[['wageincomeimp','wageincome'] + xvars].head(10)\n",
    "nls97[['wageincomeimp','wageincome']].\\\n",
    "  agg(['count','mean','std'])\n",
    "\n",
    "# add an error term\n",
    "randomadd = np.random.normal(0, lm.resid.std(), nls97.shape[0])\n",
    "randomadddf = pd.DataFrame(randomadd, columns=['randomadd'], index=nls97.index)\n",
    "nls97 = nls97.join(randomadddf, how=\"left\", on=None, validate=\"many_to_many\")\n",
    "nls97['stochasticpred'] = nls97.pred + nls97.randomadd\n",
    "nls97['wageincomeimpstoc'] = np.where(nls97.wageincome.isnull(),\\\n",
    "  nls97.stochasticpred, nls97.wageincome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入缺失-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "pd.set_option('display.width', 74)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 准备 NLS 数据\n",
    "\n",
    "nls97['hdegnum'] = \\\n",
    "  nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97['parentincome'] = \\\n",
    "  nls97.parentincome.\\\n",
    "     replace(list(range(-5,0)), \n",
    "      np.nan)\n",
    "\n",
    "wagedatalist = ['wageincome20','weeksworked20',\n",
    "   'parentincome','hdegnum']\n",
    "wagedata = \\\n",
    "  nls97.loc[nls97.weeksworked20>0, wagedatalist]\n",
    "wagedata.shape\n",
    "\n",
    "# 初始化 KNN 估算模型并填充数值\n",
    "impKNN = KNNImputer(n_neighbors=38)\n",
    "newvalues = impKNN.fit_transform(wagedata)\n",
    "wagedatalistimp = ['wageincomeimp','weeksworked20imp',\n",
    "  'parentincomeimp','hdegnumimp']\n",
    "wagedataimp = pd.DataFrame(newvalues,\n",
    "  columns=wagedatalistimp, index=wagedata.index)\n",
    "\n",
    "# 查看估算值\n",
    "wagedata = wagedata.\\\n",
    "  join(wagedataimp[['wageincomeimp','weeksworked20imp']])\n",
    "wagedata[['wageincome20','wageincomeimp','weeksworked20',\n",
    "  'weeksworked20imp']].sample(10, random_state=7)\n",
    "\n",
    "wagedata[['wageincome20','wageincomeimp']].\\\n",
    "  agg(['count','mean','std'])\n",
    "\n",
    "wagedata[['wageincome20','wageincomeimp','weeksworked20',\n",
    "  'weeksworked20imp']].sample(10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "nls97 = pd.read_csv(\"data/nls97b.csv\")\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# prepare the NLS data\n",
    "\n",
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97['degltcol'] = np.where(nls97.hdegnum<=2,1,0)\n",
    "nls97['degcol'] = np.where(nls97.hdegnum.between(3,4),1,0)\n",
    "nls97['degadv'] = np.where(nls97.hdegnum>4,1,0)\n",
    "nls97.parentincome.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "\n",
    "wagedatalist = ['wageincome','weeksworked16',\n",
    "   'parentincome','degltcol','degcol','degadv']\n",
    "wagedata = nls97[wagedatalist]\n",
    "\n",
    "# initialize a KNN imputation model and fill values\n",
    "impKNN = KNNImputer(n_neighbors=47)\n",
    "newvalues = impKNN.fit_transform(wagedata)\n",
    "wagedatalistimp = ['wageincomeimp','weeksworked16imp',\n",
    "  'parentincomeimp','degltcol','degcol','degadv']\n",
    "wagedataimp = pd.DataFrame(newvalues,\n",
    "  columns=wagedatalistimp, index=wagedata.index)\n",
    "\n",
    "# view imputed values\n",
    "wagedata = wagedata.\\\n",
    "  join(wagedataimp[['wageincomeimp','weeksworked16imp']])\n",
    "wagedata[['wageincome','weeksworked16','parentincome',\n",
    "  'degcol','degadv','wageincomeimp']].head(10)\n",
    "\n",
    "wagedata[['wageincome','wageincomeimp']].\\\n",
    "  agg(['count','mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐性缺失数据\n",
    "\n",
    "利用FuzzyWuzzy，我们可以尝试识别那些由于打字错误或不一致格式而导致的“隐性”缺失数据。\n",
    "\n",
    "例如，假设我们有一个客户信息的DataFrame，其中一个重要的字段是电话号码。电话号码由于格式不一或某些数字的缺失而可能被错误地标记为缺失。我们可以使用FuzzyWuzzy对这些疑似缺失的数据进行模糊匹配，尝试找到最接近的完整电话号码。\n",
    "\n",
    "在这段代码中，我们首先创建了一个包含疑似缺失电话号码的DataFrame。然后定义了一个函数find_similar_phone_numbers，该函数将遍历DataFrame中的电话号码列，并与给定的电话号码进行比较。如果找到相似度超过阈值的电话号码，它们将被添加到结果列表中。\n",
    "\n",
    "通过这种方式，我们可以有效地识别并处理那些看似缺失但实际上只是格式不一致或不完整的数据，从而提高数据集的准确性和完整性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "# 字符串相似度-编辑距离：指定列数据(String)，识别相似度高的重复项并删除\n",
    "\n",
    "# 导入相应数据库客户端\n",
    "import mysql.connector as mdb\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# 设置目标 table 查询语句以提取数据\n",
    "targettable = \"name\"\n",
    "\n",
    "# 使用 mysql api 和 read_sql() 从 mysql 获取和加载数据\n",
    "host = \"pdccmysql\"\n",
    "user = \"pdccuser\"\n",
    "password = \"pdccpass\"\n",
    "database = \"pdccschema\"\n",
    "connmysql = mdb.connect(host=host,database=database,user=user,password=password)\n",
    "df = pd.read_sql_table(table_name=targettable,con=connmysql)    # 生成 DataFrame\n",
    "connmysql.close()\n",
    "\n",
    "# 将 DataFrame 中的一个或多个列设置为索引\n",
    "df.set_index([\"column1_name\"], inplace=True)\n",
    "\n",
    "# 假设我们有一个包含疑似缺失电话号码的DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Carol', 'Dave'],\n",
    "    'Phone': ['(123) 456-7890', '(123) 456-780', None, '(123) 456-0000']\n",
    "})\n",
    "\n",
    "def find_similar_phone_numbers(dataframe, column_name, phone_number, threshold=80):\n",
    "    \"\"\"\n",
    "    查找与给定电话号码相似的电话号码。\n",
    "    :param dataframe: 要处理的DataFrame。\n",
    "    :param column_name: 包含电话号码的列名。\n",
    "    :param phone_number: 给定的电话号码。\n",
    "    :param threshold: 相似度阈值，默认为80。\n",
    "    :return: 相似度超过阈值的电话号码列表。\n",
    "    \"\"\"\n",
    "    similar_numbers = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if pd.notna(row[column_name]):\n",
    "            match = process.extractOne(phone_number, dataframe[column_name])\n",
    "            if match[1] > threshold:\n",
    "                similar_numbers.append(match)\n",
    "    return similar_numbers\n",
    "\n",
    "# 假设我们怀疑电话号码列的某个值被错误地标记为缺失\n",
    "suspected_missing_number = '1398888888'\n",
    "\n",
    "# 查找相似的电话号码\n",
    "similar_numbers = find_similar_phone_numbers(df, 'column_phone', suspected_missing_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入缺失-缺失森林\n",
    "\n",
    "MacOS需要：brew install libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from missforest.missforest import MissForest\n",
    "import miceforest as mf\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 清理 NLS 工资数据\n",
    "nls97['hdegnum'] = \\\n",
    "  nls97.highestdegree.str[0:1].astype('float')\n",
    "\n",
    "nls97['parentincome'] = \\\n",
    "  nls97.parentincome.\\\n",
    "     replace(list(range(-5,0)), \n",
    "      np.nan)\n",
    "\n",
    "# 加载工资收入和相关数据\n",
    "wagedatalist = ['wageincome20','weeksworked20','parentincome',\n",
    "  'hdegnum']\n",
    "wagedata = \\\n",
    "  nls97.loc[nls97.weeksworked20>0, wagedatalist]\n",
    "\n",
    "# 使用缺失森林来估算数值\n",
    "imputer = MissForest()\n",
    "wagedataimp = imputer.fit_transform(wagedata)\n",
    "wagedatalistimp = \\\n",
    "  ['wageincomeimp','weeksworked20imp','parentincomeimp']\n",
    "wagedataimp.rename(columns=\\\n",
    "   {'wageincome20':'wageincome20imp',\n",
    "   'weeksworked20':'weeksworked20imp',\n",
    "   'parentincome':'parentincomeimp'}, inplace=True)\n",
    "\n",
    "# 查看估算值\n",
    "wagedata = \\\n",
    "  wagedata.join(wagedataimp[['wageincome20imp',\n",
    "    'weeksworked20imp']])\n",
    "wagedata[['wageincome20','wageincome20imp',\n",
    "  'weeksworked20','weeksworked20imp']].\\\n",
    "  sample(10, random_state=7)\n",
    "\n",
    "wagedata[['wageincome20','wageincome20imp',\n",
    "  'weeksworked20','weeksworked20imp']].\\\n",
    "  agg(['count','mean','std'])\n",
    "\n",
    "# 改为运行多重插值法(miceforest)\n",
    "kernel = mf.ImputationKernel(\n",
    "  data=wagedata[wagedatalist].reset_index(),\n",
    "  save_all_iterations_data=True,\n",
    "  random_state=1,\n",
    "  num_datasets=3,\n",
    "  mean_match_candidates=5\n",
    ")\n",
    "kernel.mice(3,verbose=True)\n",
    "\n",
    "wagedataimpmice = kernel.complete_data()\n",
    "\n",
    "wagedataimpmice.rename(columns=\\\n",
    "  {'wageincome20':'wageincome20impmice',\n",
    "  'weeksworked20':'weeksworked20impmice',\n",
    "  'parentincome':'parentincomeimpmice'}, \n",
    "  inplace=True)\n",
    "\n",
    "wagedata = wagedata[wagedatalist].\\\n",
    " join(wagedataimpmice[['wageincome20impmice',\n",
    "   'weeksworked20impmice']])\n",
    " \n",
    "wagedata[['wageincome20','wageincome20impmice',\n",
    "  'weeksworked20','weeksworked20impmice']].\\\n",
    "  agg(['count','mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and scikit learn's KNNImputer module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "import os\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "nls97 = pd.read_csv(\"/data/nls97b.csv\")\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# clean the NLS wage data\n",
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97.parentincome.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "nls97['degltcol'] = np.where(nls97.hdegnum<=2,1,0)\n",
    "nls97['degcol'] = np.where(nls97.hdegnum.between(3,4),1,0)\n",
    "nls97['degadv'] = np.where(nls97.hdegnum>4,1,0)\n",
    "\n",
    "# load the wage income and associated data\n",
    "wagedatalist = ['wageincome','weeksworked16','parentincome',\n",
    "  'degltcol','degcol','degadv']\n",
    "wagedata = nls97[wagedatalist]\n",
    "\n",
    "# use miss forest to impute values\n",
    "imputer = MissForest()\n",
    "newvalues = imputer.fit_transform(wagedata)\n",
    "wagedatalistimp = ['wageincomeimp','weeksworked16imp','parentincomeimp',\n",
    "  'degltcol','degcol','degadv']\n",
    "wagedataimp = pd.DataFrame(newvalues, columns=wagedatalistimp, index=wagedata.index)\n",
    "\n",
    "\n",
    "# view imputed values\n",
    "wagedataimp\n",
    "wagedata = wagedata.join(wagedataimp[['wageincomeimp','weeksworked16imp']])\n",
    "wagedata[['wageincome','weeksworked16','parentincome',\n",
    "  'degcol','degadv','wageincomeimp']].head(10)\n",
    "\n",
    "wagedata[['wageincome','wageincomeimp','weeksworked16','weeksworked16imp']].\\\n",
    "  agg(['count','mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入缺失-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasai.llm.openai import OpenAI\n",
    "from pandasai import SmartDataframe\n",
    "llm = OpenAI(api_token=\"Your API Key\")\n",
    "\n",
    "pd.set_option('display.width', 72)\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 220)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "\n",
    "# 加载数据帧并创建智能数据帧对象\n",
    "nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "\n",
    "# 设置学位和父母收入变量\n",
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('category')\n",
    "nls97['parentincome'] = \\\n",
    "  nls97.parentincome.\\\n",
    "  replace(list(range(-5,0)),\n",
    "  np.nan)\n",
    "\n",
    "wagedatalist = ['wageincome20','weeksworked20',\n",
    "   'parentincome','hdegnum']\n",
    "wagedata = nls97[wagedatalist]\n",
    "\n",
    "wagedatasdf = SmartDataframe(wagedata, config={\"llm\": llm})\n",
    "\n",
    "# 显示摘要统计\n",
    "wagedatasdf.chat(\"Show the counts, means, and standard deviations as table\")\n",
    "\n",
    "# 根据平均数推算遗漏\n",
    "wagedatasdf = \\\n",
    "  wagedatasdf.chat(\"Impute missing values based on average.\")\n",
    "  \n",
    "wagedatasdf.chat(\"Show the counts, means, and standard deviations as table\")\n",
    "\n",
    "wagedatasdf.hdegnum.value_counts(dropna=False).sort_index()\n",
    "wagedatasdf = \\\n",
    "  wagedatasdf.chat(\"Impute missings based on most frequent value\")\n",
    "wagedatasdf.hdegnum.value_counts(dropna=False).sort_index()\n",
    "\n",
    "# 改用估算缺失率函数\n",
    "wagedatasdf = SmartDataframe(wagedata, config={\"llm\": llm})\n",
    "\n",
    "wagedatasdf = \\\n",
    "  wagedatasdf.impute_missing_values()\n",
    "wagedatasdf.chat(\"Show the counts, means, and standard deviations as table\")\n",
    "\n",
    "# 用 KNN 计算\n",
    "wagedatasdf = SmartDataframe(wagedata, config={\"llm\": llm})\n",
    "wagedatasdf = wagedatasdf.chat(\"Impute missings for float variables based on knn with 47 neighbors\")\n",
    "wagedatasdf.chat(\"Show the counts, means, and standard deviations as table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
