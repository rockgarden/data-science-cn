{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 构造序列\n",
    "series1 = pd.Series([2.8,3.01,8.99,8.59,5.18])\n",
    "series2 = pd.Series([2.8,3.01,8.99,8.59,5.18],index = ['a','b','c','d','e'],name ='这是一个series')\n",
    "series3 = pd.Series({'北京':2.8,'上海':3.01,'广东':8.99,'江苏':8.59,'浙江':5.18})\n",
    "#series方法\n",
    "series2.values\n",
    "series3.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dafaframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dafaframe其实就是一个二维表结构，是数据分析中，最常用的数据结构\n",
    "list1 = [['张三',23,'男'],['李四',27,'女'],['王二',26,'女']]#使用嵌套列表\n",
    "df1 = pd.DataFrame(list1,columns=['姓名','年龄','性别'])\n",
    "type(df1)\n",
    "df2 = pd.DataFrame({'姓名':['张三','李四','王二'],'年龄':[23,27,26],'性别':['男','女','女']}) #使用字典,字典的键被当成列名\n",
    "df2\n",
    "array1 = np.array([['张三',23,'男'],['李四',27,'女'],['王二', 26,'女']]) #使用numpy\n",
    "df3 = pd.DataFrame(array1,columns=['姓名','年龄','性别'],index = ['a','b','c'] )\n",
    "#dataframe方法\n",
    "df2.to_numpy()\n",
    "df2.index\n",
    "df2.columns\n",
    "df2.dtypes\n",
    "df2.ndim\n",
    "df2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str})\n",
    "# 查看数据\n",
    "df.info()\n",
    "df.head(5)  # 查看前5行\n",
    "df.tail(5)  # 查看后5行\n",
    "df.columns  # 查看变量名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单索引\n",
    "df['user_id']\n",
    "df['user_id'][1:5]  # 第二行到第五行\n",
    "# 多个变量选择\n",
    "df[['user_id','buy_mount','day']][:5]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3:4] # 选择行索引标签\n",
    "df.loc[:,['user_id','buy_mount']]   # 选择某两列\n",
    "df.loc[1:3,['user_id','buy_mount']] # loc在这里选择的是行索引标签\n",
    "df.loc[df.user_id =='786295544',['user_id','buy_mount','day']]\n",
    "df.loc[(df.user_id =='786295544') | (df.user_id =='444069173'),['user_id','buy_mount','day']]   # 多个条件选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:4]  # 按照位置来选择第二列到第四列\n",
    "df.iloc[:,[0,2]]    # 按照位置来选择第1列和第3列\n",
    "df.iloc[3,[1,2]]    # 选择第4行，第2列和第3列数据, 这里的3代表的不是索引标签而是位置\n",
    "df.iloc[2:7,[1,2]]  # 选择第3行到第7行，第2列和第3列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc和iloc的区别\n",
    "print(df.loc[2:7])\n",
    "print(df.iloc[2:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加一列,购买量,购买量超过3的为高，低于3的为底\n",
    "df['购买量'] = np.where(df['buy_mount'] >3,'高','低')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这一列取出来，赋值给对象auction_id,然后在数据中删除这一列，再将其添加进去\n",
    "auction_id = df['auction_id']\n",
    "del df['auction_id']\n",
    "print(df.head(1))\n",
    "df.insert(0, 'auction_id', auction_id)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/ships.csv')\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "print(df.iloc[-1]['name'])\n",
    "df['name'] = df['name'].str.strip()\n",
    "print(df.iloc[-1]['name'])\n",
    "import numpy as np\n",
    "mask = df['name'].str.strip() == ''\n",
    "df.loc[mask, 'name'] = np.nan\n",
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/cart.csv', parse_dates=['date'])\n",
    "print(df)\n",
    "\n",
    "df['amount'].fillna(1, inplace=True)\n",
    "print(df)\n",
    "\n",
    "most_common = df['name'].mode()[0]\n",
    "df['name'].fillna(most_common, inplace=True)\n",
    "print(df)\n",
    "\n",
    "df['date'].fillna(method='ffill', inplace=True)\n",
    "print(df)\n",
    "\n",
    "import numpy as np\n",
    "prices = df.groupby('name')['price'].transform(np.mean)\n",
    "print(prices)\n",
    "\n",
    "df['price'].fillna(prices, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/metrics.csv', parse_dates=['time'])\n",
    "print(df)\n",
    "\n",
    "df = pd.melt(\n",
    "    df,\n",
    "    value_vars=['cpu', 'memory'],\n",
    "    id_vars=['time'],\n",
    "    var_name='metric',\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/points.csv')\n",
    "print(df.dtypes)\n",
    "\n",
    "def asint(val):\n",
    "    return int(val, base=0)\n",
    "\n",
    "df['color'] = df['color'].apply(asint)\n",
    "print(df.dtypes)\n",
    "\n",
    "bools = {\n",
    "    'yes': True,\n",
    "    'no': False,\n",
    "}\n",
    "df['visible'] = df['visible'].map(bools)\n",
    "df.dtypes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = '2021-06.csv'\n",
    "path = 'data/'\n",
    "df = pd.read_csv(path+csv_file)\n",
    "print(df)\n",
    "df['date'] = csv_file[:-len('.csv')]\n",
    "print(df)\n",
    "times = df['time'].str.split('-', expand=True)\n",
    "times.columns = ['start', 'end']\n",
    "print(times)\n",
    "df = pd.concat([df, times], axis=1)\n",
    "print(df)\n",
    "\n",
    "df['start'] = pd.to_datetime(\n",
    "    df['date'].str.cat(df['start'], sep='T')\n",
    ")\n",
    "df['end'] = pd.to_datetime(\n",
    "    df['date'].str.cat(df['end'], sep='T')\n",
    ")\n",
    "print(df)\n",
    "\n",
    "print((df['end'] - df['start']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/rides.csv')\n",
    "print(df)\n",
    "# 评估描述 DataFrame 列操作的字符串。这就允许 eval 运行任意代码，如果将用户输入传递给此函数，就可能导致代码注入。\n",
    "mask = df.eval('name.isnull() | distance <= 0')\n",
    "print(mask)\n",
    "\n",
    "df = df[~mask]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据帧范式验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/ships.csv')\n",
    "\n",
    "import pandera as pa\n",
    "\n",
    "# 设定数据帧范式\n",
    "schema = pa.DataFrameSchema({\n",
    "    # 创建列验证器对象\n",
    "    'name': pa.Column(pa.String),\n",
    "    'lat': pa.Column(pa.Float),\n",
    "    'lng': pa.Column(pa.Float),\n",
    "})\n",
    "\n",
    "# 根据模式规范验证数据帧\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema({\n",
    "    'name': pa.Column(pa.String),\n",
    "    'lat': pa.Column(\n",
    "        pa.Float,\n",
    "        nullable=True,\n",
    "        checks=pa.Check(\n",
    "            lambda v: v >= -90 and v <= 90,\n",
    "            element_wise=True,\n",
    "        ),\n",
    "    ),\n",
    "    'lng': pa.Column(\n",
    "        pa.Float,\n",
    "        nullable=True,\n",
    "        checks=pa.Check(\n",
    "            lambda v: v >= -180 and v <= 180,\n",
    "            element_wise=True,\n",
    "        ),\n",
    "    ),\n",
    "})\n",
    "\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "size = 5\n",
    "generator = np.random.default_rng(5)\n",
    "df = pd.DataFrame({\n",
    "    'time': pd.date_range('2021', freq='17s', periods=size),\n",
    "    'name': ['cpu'] * size,\n",
    "    'value': generator.standard_normal() * 40,\n",
    "})\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "schema = pa.schema([\n",
    "    ('time', pa.timestamp('ms')),\n",
    "    ('name', pa.string()),\n",
    "    ('value', pa.float64()),\n",
    "])\n",
    "print(type(df['time'][0]))\n",
    "\n",
    "out_file = 'data/metrics.parquet'\n",
    "# 将数据帧写入二进制 parquet 格式。\n",
    "df.to_parquet(out_file, schema=schema)\n",
    "print(pd.read_parquet(out_file))\n",
    "\n",
    "df['time'] = df['time'].astype(str)\n",
    "print(type(df['time'][0]))\n",
    "\n",
    "# 转换格式后schema校验将报ArrowTypeError\n",
    "# df.to_parquet(out_file, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/orders.csv', parse_dates=['time'])\n",
    "\n",
    "# 行校验\n",
    "def is_valid_row(row):\n",
    "    if row['time'] < pd.Timestamp('1900'):\n",
    "        return False\n",
    "    if pd.isnull(row['symbol']) or row['symbol'].strip() == '':\n",
    "        return False\n",
    "    if row['price'] <= 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "ok_df = df[df.apply(is_valid_row, axis=1)]\n",
    "\n",
    "num_bad = len(df) - len(ok_df)\n",
    "percent_bad = num_bad/len(df) * 100\n",
    "print(f'{percent_bad:.2f}% bad rows')\n",
    "if num_bad > 0:\n",
    "    bad_rows = df[~df.index.isin(ok_df.index)]\n",
    "    print('bad rows:')\n",
    "    print(bad_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时删除多个变量，需要以列表的形式\n",
    "# labels表示删除的数据, axis表示作用轴，inplace=True表示是否对原数据生效,\n",
    "# axis=0按行操作, axis=1按列操作\n",
    "df.drop(labels = ['property', '购买量'],axis = 1)   # 1代表沿着列的方向\n",
    "# 按行删除法\n",
    "df.drop(labels = [3,4], axis= 0)    # 删除索引标签3和4对应的行\n",
    "df.drop(labels= range(6,11), axis=0)    # 删除索引名称1到10,注意range迭代器产生的是1到10\n",
    "# 查看\n",
    "df\n",
    "# 默认情况下，原始DataFrame保持不变，并返回一个新的DataFrame。如果参数inplace设置为True，则将更改原始DataFrame。在这种情况下，不会返回任何新的DataFrame，并且返回值为None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str},index_col=0)\n",
    "# 按行名指定（行标签）删除行，行标签所在列为index_col\n",
    "df.drop(labels= ['307215255'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多行多列的删除\n",
    "df.drop(index=['532110457', '786295544', '917056007'],\n",
    "              columns=['buy_mount', 'cat1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.index[[1, 3, 5]],\n",
    "              columns=df.columns[[1, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据修改和查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/sam_tianchi_mum_baby.csv',encoding = 'utf-8',dtype =str)\n",
    "print(df1.head(1))\n",
    "# 将gender为0的改为女性、1改为男性、2改为未知\n",
    "df1.loc[df1['gender'] =='0','gender'] ='女性'\n",
    "df1.loc[df1['gender'] =='1','gender'] ='男性'\n",
    "df1.loc[df1['gender'] =='2','gender'] ='未知'\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改列标签和行索引名称\n",
    "df1.rename(columns = {'user_id':'用户ID','birthday':'出生日期','gender':'性别'},inplace = True)\n",
    "df1.rename(index = {1:'one',10:'ten' },inplace = True) # 修改行索引名称\n",
    "df1.reset_index(drop=True,inplace=True) # 重置索引\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件查询\n",
    "df[df.buy_mount > 3]    # 性别等于未知\n",
    "df[~(df.buy_mount > 3)] # ~代表非\n",
    "df[(df.buy_mount > 3) & (df.day > 20140101)]    # 多条件查询\n",
    "# 使用isin()方法\n",
    "df[df['auction_id'].isin([41098319944, 17916191097,21896936223])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xlrd -i https://pypi.tuna.tsinghua.edu.cn/simple \n",
    "# 纵向堆叠可以理解为把不同的表，字段名称一样，整合在一起\n",
    "# 关联字段必须类型一致\n",
    "df = pd.read_csv('data/baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str}) # 交易数据\n",
    "df1 = pd.read_csv('data/sam_tianchi_mum_baby.csv',encoding = 'utf-8',dtype =str)    # 婴儿信息\n",
    "df2 = pd.merge(left = df, right=df1,  how='inner',  left_on='user_id', right_on = 'user_id', validate=\"many_to_many\")    # 内连接\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/heights.csv')\n",
    "max_heights = pd.DataFrame([[1, 32],], columns=['grade', 'max_height'])\n",
    "print(max_heights)\n",
    "\n",
    "mdf = pd.merge(df, max_heights, how='left', on=None, validate=\"many_to_many\")\n",
    "print(mdf)\n",
    "\n",
    "df[mdf['height'] > mdf['max_height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/online_order.csv',encoding = 'gbk',dtype={'customer':str,'order':str})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)  # 查看数据\n",
    "grouped = df.groupby('weekday') # 创建分组对象,按照星期进行分组\n",
    "grouped.sum()['total_items']    # 计算不同的星期，商品数量的总和\n",
    "grouped = df.groupby(by =['customer','weekday'])    # 创建分组对象,按照用户和星期\n",
    "grouped.sum()['total_items'].head(50)   # 调用方法,计算不同的用户周一到周天的订购商品数量的总和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实操"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定位不良记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/rides.csv')\n",
    "# 缺失值记录\n",
    "null_mask = df.isnull().any(axis=1)\n",
    "# plate少于3个大写字母或数字的组合\n",
    "plate_mask = ~df['plate'].str.match(r'^[0-9A-Z]{3,}', na=False)\n",
    "# distance小于0\n",
    "dist_mask = df['distance'] < 0\n",
    "# 合并所有有不良值的记录\n",
    "mask = null_mask | plate_mask | dist_mask\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据修复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/workshops.csv')\n",
    "print(df)\n",
    "\n",
    "\"\"\"\n",
    "Fix the data frame. At the end, row should have the following columns:\n",
    "- start: pd.Timestemap\n",
    "- end: pd.Timestamp\n",
    "- name: str\n",
    "- topic: str (python or go)\n",
    "- earnings: np.float64\n",
    "\"\"\"\n",
    "\n",
    "# Fill Year & Month\n",
    "df['Year'].fillna(method='ffill', inplace=True)\n",
    "df['Month'].fillna(method='ffill', inplace=True)\n",
    "print(df)\n",
    "\n",
    "# 仅保留 earnings 非空\n",
    "df = df[pd.notnull(df['Earnings'])].copy()\n",
    "print(df)\n",
    "\n",
    "# %%\n",
    "def as_date(row, col):\n",
    "    year = int(row['Year'])\n",
    "    month = row['Month']\n",
    "    day = int(row[col])\n",
    "    ts = f'{month} {day}, {year}'\n",
    "    return pd.to_datetime(ts, format='%B %d, %Y')\n",
    "\n",
    "df['start'] = df.apply(as_date, axis=1, args=('Start',))\n",
    "df['end'] = df.apply(as_date, axis=1, args=('End',))\n",
    "print(df)\n",
    "\n",
    "# %% 根据关键定 Extract topic\n",
    "def topic(name):\n",
    "    if 'go' in name:\n",
    "        return 'go'\n",
    "    if 'python' in name:\n",
    "        return 'python'\n",
    "\n",
    "df['topic'] = df['Name'].str.lower().apply(topic)\n",
    "print(df)\n",
    "\n",
    "# %% Earnings\n",
    "import numpy as np\n",
    "df['earnings'] = pd.to_numeric(\n",
    "    df['Earnings'].str.replace(r'[$,]', '')\n",
    ").astype(np.float64)\n",
    "print(df)\n",
    "\n",
    "# %% Cleanup\n",
    "df = df[['start', 'end', 'Name', 'topic', 'earnings']]\n",
    "df.rename(columns={'Name': 'name'}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical\n",
    "\n",
    "pandas.Categorical(val, categories = None, ordered = None, dtype = None) ： 表示一个分类变量。\n",
    "Categorical 是一种 pandas 数据类型，与统计中的分类变量相对应。此类变量具有固定且数量有限的可能值。例如，成绩、性别、血型等。\n",
    "此外，对于分类变量，逻辑顺序与分类数据（如 “一”、“二”、“三”）不同。但这些变量的排序使用逻辑顺序。\n",
    "\n",
    "[courses](https://www.geeksforgeeks.org/python-pandas-categorical/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "# Categorical using dtype\n",
    "c = pd.Series([\"a\", \"b\", \"d\", \"a\", \"d\"], dtype =\"category\")\n",
    "print (\"\\nCategorical without pandas.Categorical() : \\n\", c)\n",
    " \n",
    " \n",
    "c1 = pd.Categorical([1, 2, 3, 1, 2, 3])\n",
    "print (\"\\n\\nc1 : \", c1)\n",
    " \n",
    "c2 = pd.Categorical(['e', 'm', 'f', 'i',\n",
    "                     'f', 'e', 'h', 'm' ])\n",
    "print (\"\\nc2 : \", c2)\n",
    "\n",
    "c3 = pd.Categorical(['e', 'm', 'f', 'i',\n",
    "                     'f', 'e', 'h', 'm' ], ordered = True)\n",
    "print (\"\\nc3 : \", c3)\n",
    "\n",
    "# Mixed categories\n",
    "c4 = pd.Categorical(['a', 2, 3, 1, 2, 3])\n",
    "print (\"\\nc4 : \", c4)\n",
    " \n",
    "c5 = pd.Categorical(['a', 2, 3, 1, 2, 3], ordered = True)\n",
    "print (\"\\nc5 : \", c5)\n",
    "\n",
    "# using categories attribute\n",
    "c6 = pd.Categorical([1, 2, 3, 1, 2, 3], categories = [4, 1, 3, 5])\n",
    "print (\"\\nc6 : \", c6)\n",
    " \n",
    "print(\"\\n\\nSeries : \\n\", pd.Series(c6))\n",
    " \n",
    "df = pd.DataFrame({\"A\":[1, 2, 3, 1, 2, 3]})\n",
    "df[\"B\"] = c6\n",
    "print (\"\\n\\nDataframe : \\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
